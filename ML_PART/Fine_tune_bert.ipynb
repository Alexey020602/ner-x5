{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c494d8a02e1c4a7d9ed97660957fafa3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e5a25da844849ae82abf8b127e858dc","IPY_MODEL_7be641bdc7634e2a99e7346b7eac3273","IPY_MODEL_f5a01bce0ddd4b33bfe67dd968636230"],"layout":"IPY_MODEL_9ffa3db6e0044dd1880eabe7d5253431"}},"6e5a25da844849ae82abf8b127e858dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_340eddd27a594d37904be54ef8fac165","placeholder":"​","style":"IPY_MODEL_5d2660127dd74ab892442b165407878d","value":"tokenizer_config.json: 100%"}},"7be641bdc7634e2a99e7346b7eac3273":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29174e7e82e24a83856ab9d88d5ab259","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a96d20f6a8c490ab4d67f6c2f6a7a64","value":24}},"f5a01bce0ddd4b33bfe67dd968636230":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e57da65ac3ac4731928672d2d2826e46","placeholder":"​","style":"IPY_MODEL_0dcc587a1854442abf86c35def9eeb34","value":" 24.0/24.0 [00:00&lt;00:00, 1.16kB/s]"}},"9ffa3db6e0044dd1880eabe7d5253431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340eddd27a594d37904be54ef8fac165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2660127dd74ab892442b165407878d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29174e7e82e24a83856ab9d88d5ab259":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a96d20f6a8c490ab4d67f6c2f6a7a64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e57da65ac3ac4731928672d2d2826e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dcc587a1854442abf86c35def9eeb34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82417566418742caa58a324a999d4f58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ff4a412d1ce4f1086796a54d2e90c01","IPY_MODEL_31056a7f9a6f4129b0b34cbade203f92","IPY_MODEL_ed2951419f1241128d5976c93001be65"],"layout":"IPY_MODEL_6d15fee69f2f480abca6d3c7a74e2c4f"}},"4ff4a412d1ce4f1086796a54d2e90c01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b870554cb684c2f8931370a95a81261","placeholder":"​","style":"IPY_MODEL_925230ca57554eca9a22ad2aca87c85f","value":"config.json: 100%"}},"31056a7f9a6f4129b0b34cbade203f92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38de396dae824bc696a9a08b74b297d6","max":642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c288b9c0bfb243848311106f51bdb9fe","value":642}},"ed2951419f1241128d5976c93001be65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fea4c3daf1fe48b1a2955508eebe36ea","placeholder":"​","style":"IPY_MODEL_7ec6abc1d8f544d5a9432b412a350481","value":" 642/642 [00:00&lt;00:00, 20.3kB/s]"}},"6d15fee69f2f480abca6d3c7a74e2c4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b870554cb684c2f8931370a95a81261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925230ca57554eca9a22ad2aca87c85f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38de396dae824bc696a9a08b74b297d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c288b9c0bfb243848311106f51bdb9fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fea4c3daf1fe48b1a2955508eebe36ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec6abc1d8f544d5a9432b412a350481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"900bc261aed2432682721fdc23bb95b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e6eff9d0874450e99f914f3c7c08af7","IPY_MODEL_db710deca44045a19a7fd16cdc362e6e","IPY_MODEL_a9b12480c65e470db9bd1d91c95ce984"],"layout":"IPY_MODEL_8df54d3af535400b8fe87355557828cc"}},"4e6eff9d0874450e99f914f3c7c08af7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f474710b6aaa41f884e42965c8b837fa","placeholder":"​","style":"IPY_MODEL_8994b65812804e2e9d3c9d524097b224","value":"vocab.txt: "}},"db710deca44045a19a7fd16cdc362e6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e36e66a210a04ca3b88850de296cf40c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_835dd1a29a6a4ee686719dda1b1da460","value":1}},"a9b12480c65e470db9bd1d91c95ce984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22307cbac2af41cc94a9ff446860e1e8","placeholder":"​","style":"IPY_MODEL_44cd4339463f41edab30620f9cf75b5d","value":" 1.65M/? [00:00&lt;00:00, 26.8MB/s]"}},"8df54d3af535400b8fe87355557828cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f474710b6aaa41f884e42965c8b837fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8994b65812804e2e9d3c9d524097b224":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e36e66a210a04ca3b88850de296cf40c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"835dd1a29a6a4ee686719dda1b1da460":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22307cbac2af41cc94a9ff446860e1e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44cd4339463f41edab30620f9cf75b5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2459f9b514144af59798f3e0a61a89c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da764975d79b4456ac7f8febc7e97b97","IPY_MODEL_eb791fe3759c4a47bf427fcac3959243","IPY_MODEL_8c9cc802476d41b98cf4b126808cd03d"],"layout":"IPY_MODEL_920ae9b994b74c769230ec1344ebb876"}},"da764975d79b4456ac7f8febc7e97b97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea6cb82c767c4f0391631dd16bf15930","placeholder":"​","style":"IPY_MODEL_6d177c1bc23b4ea3b36e81c91c3bd7f1","value":"special_tokens_map.json: 100%"}},"eb791fe3759c4a47bf427fcac3959243":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8bde1a57234b4d8538a31212cc0b85","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11dfbf5977d9402e9f9cfe0e732ce417","value":112}},"8c9cc802476d41b98cf4b126808cd03d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_131c19b31d54413db8779bf939fa40c7","placeholder":"​","style":"IPY_MODEL_c99be27aef434cfab4c2f1ace3c35255","value":" 112/112 [00:00&lt;00:00, 2.71kB/s]"}},"920ae9b994b74c769230ec1344ebb876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea6cb82c767c4f0391631dd16bf15930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d177c1bc23b4ea3b36e81c91c3bd7f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed8bde1a57234b4d8538a31212cc0b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11dfbf5977d9402e9f9cfe0e732ce417":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"131c19b31d54413db8779bf939fa40c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c99be27aef434cfab4c2f1ace3c35255":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"0jU5kuXfijpT","executionInfo":{"status":"error","timestamp":1759225625993,"user_tz":-180,"elapsed":7451,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"710e83e2-d068-4384-839a-23829b75e857"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-685145057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mNAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Alexander\"\u001b[0m           \u001b[0;31m# твоё имя для git\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# === Подключение Google Drive ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mPROJECTS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'$PROJECTS_DIR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","import getpass, os\n","\n","# === Настройка проекта ===\n","USER = \"tokarevdr\"   # твой GitHub username\n","REPO = \"entities-extraction-x5\"            # название репозитория\n","EMAIL = \"fedorov.alexander.04@gmail.com\"    # твоя почта для git\n","NAME = \"Alexander\"           # твоё имя для git\n","# === Подключение Google Drive ===\n","drive.mount('/content/drive')\n","PROJECTS_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n","%cd $PROJECTS_DIR\n","# === GitHub авторизация ===\n","token = getpass.getpass('Введи GitHub PAT токен: ')\n","os.environ[\"GITHUB_TOKEN\"] = token\n","\n","\n","# === Проверяем: если репозиторий ещё не скачан, клонируем ===\n","if not os.path.exists(f\"{PROJECTS_DIR}/{REPO}/ML PART\"):\n","    print('Заново склонировали репу')\n","    !git clone https://{USER}:{os.environ[\"GITHUB_TOKEN\"]}@github.com/{USER}/{REPO}.git\n","# === Переходим в папку проекта ===\n","%cd {REPO}/{'ML_PART'}\n","\n","# === Настройка Git ===\n","!git config --global user.email \"{EMAIL}\"\n","!git config --global user.name \"{NAME}\"\n","!git remote set-url origin https://{USER}:{os.environ[\"GITHUB_TOKEN\"]}@github.com/{USER}/{REPO}.git\n","\n","print(\"✅ Всё готово! Рабочая папка:\", os.getcwd())\n"]},{"cell_type":"code","source":[],"metadata":{"id":"_69974-nHwLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Установка зависимостей\n","!pip install -r requirements_bert.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43TOp5KPoqEB","executionInfo":{"status":"ok","timestamp":1759217852569,"user_tz":-180,"elapsed":4237,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"d0f39f1d-c6e2-443b-9337-8fae73354885"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 2)) (2.8.0+cu126)\n","Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 3)) (4.35.2)\n","Requirement already satisfied: huggingface_hub==0.20.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 6)) (0.20.3)\n","Requirement already satisfied: accelerate==0.24.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 7)) (0.24.1)\n","Requirement already satisfied: tokenizers==0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 8)) (0.15.0)\n","Requirement already satisfied: datasets==2.14.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 9)) (2.14.7)\n","Requirement already satisfied: pandas==2.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 12)) (2.1.4)\n","Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 13)) (1.26.0)\n","Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 14)) (3.7.2)\n","Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 15)) (1.3.2)\n","Requirement already satisfied: TorchCRF==1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 18)) (1.1.0)\n","Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_bert.txt (line 21)) (1.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (2023.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements_bert.txt (line 2)) (3.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (2.32.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.35.2->-r requirements_bert.txt (line 3)) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.24.1->-r requirements_bert.txt (line 7)) (5.9.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (18.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (0.7)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (0.3.7)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.14.7->-r requirements_bert.txt (line 9)) (3.12.15)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4->-r requirements_bert.txt (line 12)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4->-r requirements_bert.txt (line 12)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4->-r requirements_bert.txt (line 12)) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (4.60.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (1.4.9)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (11.3.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.2->-r requirements_bert.txt (line 14)) (3.0.9)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements_bert.txt (line 15)) (1.16.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements_bert.txt (line 15)) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2->-r requirements_bert.txt (line 15)) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.14.7->-r requirements_bert.txt (line 9)) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.4->-r requirements_bert.txt (line 12)) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.2->-r requirements_bert.txt (line 3)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.2->-r requirements_bert.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.2->-r requirements_bert.txt (line 3)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.35.2->-r requirements_bert.txt (line 3)) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->-r requirements_bert.txt (line 2)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->-r requirements_bert.txt (line 2)) (3.0.2)\n"]}]},{"cell_type":"code","source":["! pip install --upgrade onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKM-_g4rH0SC","executionInfo":{"status":"ok","timestamp":1759217860998,"user_tz":-180,"elapsed":8426,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"4555dc1a-a16c-489f-a61a-446983859278"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.26.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import getpass, os, json, random, time\n","import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import AdamW\n","\n","# Импорты transformers с обработкой ошибок\n","try:\n","    from transformers import AutoTokenizer, AutoModelForTokenClassification, get_scheduler\n","    print(\"✅ Transformers успешно импортированы\")\n","except ImportError as e:\n","    print(f\"❌ Ошибка импорта transformers: {e}\")\n","    !pip install transformers==4.35.2\n","    from transformers import AutoTokenizer, AutoModelForTokenClassification, get_scheduler\n","\n","try:\n","    from TorchCRF import CRF\n","    print(\"✅ TorchCRF успешно импортирован\")\n","except ImportError as e:\n","    print(f\"❌ Ошибка импорта TorchCRF: {e}\")\n","    !pip install TorchCRF==1.1.0\n","    from TorchCRF import CRF\n","\n","import ast\n","import traceback\n","from module import calculate_ner_metrics, calculate_macro_f1, process_submission_bert, \\\n","                  setup_hf_login, save_bert_to_hf, load_bert_from_hf, list_my_repos, check_repo_exists, NERModelWithCRF\n","from torch.nn.utils.rnn import pad_sequence"],"metadata":{"id":"cU-8Ca9forrD","executionInfo":{"status":"ok","timestamp":1759217868100,"user_tz":-180,"elapsed":7094,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"838bf2e6-07ca-421b-9825-cb221de1e827"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _torch_pytree._register_pytree_node(\n"]},{"output_type":"stream","name":"stdout","text":["✅ Transformers успешно импортированы\n","✅ TorchCRF успешно импортирован\n"]}]},{"cell_type":"code","source":["# --- Основные пути для сохранения результатов ---\n","WHERE_DATA = 'cleared_data'\n","BASE_MODEL_NAME = \"bert\"\n","OUT_DIR = f\"OUTPUT/{WHERE_DATA}/{BASE_MODEL_NAME}\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","FINAL_METRICS_PATH = f\"{OUT_DIR}/final_training_metrics_per_epoch.csv\"\n","MODEL_PATH = f'MODELS/{WHERE_DATA}/{BASE_MODEL_NAME}'\n","os.makedirs(MODEL_PATH, exist_ok=True)\n","DATA_DIR = f'data/{WHERE_DATA}/'\n","PATIENCE = 3\n","SEED = 42\n"],"metadata":{"id":"bO4KcUNr0ASv","executionInfo":{"status":"ok","timestamp":1759217868808,"user_tz":-180,"elapsed":705,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Hugging Face настройки\n","HF_TOKEN= getpass.getpass('Введи HFT токен: ')\n","HF_USERNAME = \"alexflex04\"\n","BERT_REPO_NAME = f\"{HF_USERNAME}/NER_{WHERE_DATA}_bert\"\n","\n","setup_hf_login(HF_TOKEN)"],"metadata":{"id":"0KGUxpTbJQSH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759218003368,"user_tz":-180,"elapsed":134557,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"a62ed379-550e-4d17-bd43-e7c01ea68c28"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Введи HFT токен: ··········\n","Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","✅ Авторизация HF настроена\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"t_VWEzvBF9nH","executionInfo":{"status":"ok","timestamp":1759218003381,"user_tz":-180,"elapsed":10,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"mFL3k8dl0FOh","executionInfo":{"status":"ok","timestamp":1759218003383,"user_tz":-180,"elapsed":1,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Используемое устройство: {device}\")"],"metadata":{"id":"jgkUd-P9ov1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759218003446,"user_tz":-180,"elapsed":62,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"c06eb265-f00f-46bc-bfaa-e376113eddfb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Используемое устройство: cuda\n"]}]},{"cell_type":"code","source":["CONFIG = {\n","    \"model_checkpoint\": \"DeepPavlov/rubert-base-cased\",\n","    \"num_epochs\": 20,\n","    \"batch_size\": 32,\n","    \"learning_rate\": 2e-5,\n","    \"weight_decay\": 0.01,\n","    \"patience\": PATIENCE,\n","    \"max_length\": 128,\n","    \"label_list\": [\"O\", \"B-TYPE\", \"I-TYPE\", \"B-BRAND\", \"I-BRAND\", \"B-VOLUME\", \"I-VOLUME\", \"B-PERCENT\", \"I-PERCENT\"],\n","    \"id2label\": {i: label for i, label in enumerate([\"O\", \"B-TYPE\", \"I-TYPE\", \"B-BRAND\", \"I-BRAND\", \"B-VOLUME\", \"I-VOLUME\", \"B-PERCENT\", \"I-PERCENT\"])},\n","    \"label2id\": {label: i for i, label in enumerate([\"O\", \"B-TYPE\", \"I-TYPE\", \"B-BRAND\", \"I-BRAND\", \"B-VOLUME\", \"I-VOLUME\", \"B-PERCENT\", \"I-PERCENT\"])},\n","    \"metrics_csv\": f\"{OUT_DIR}/screening_metrics.csv\",\n","    \"submission_input\": f\"{DATA_DIR}/submission.csv\",\n","    \"submission_output\": f\"{OUT_DIR}/submission_response_bert.csv\"\n","}\n"],"metadata":{"id":"j_L-1esl0O58","executionInfo":{"status":"ok","timestamp":1759218003452,"user_tz":-180,"elapsed":6,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Загрузка данных\n","train_split = pd.read_csv(f\"{DATA_DIR}train.csv\")\n","valid_data = pd.read_csv(f\"{DATA_DIR}val.csv\")\n","\n","def parse_row_to_example(row):\n","    try:\n","        ann = ast.literal_eval(row['annotation'])\n","    except Exception:\n","        ann = []\n","    return (row['sample'], {'entities': ann})\n","\n","train_data = [parse_row_to_example(row) for _, row in train_split.iterrows()]\n","valid_data = [parse_row_to_example(row) for _, row in valid_data.iterrows()]\n","\n","tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"model_checkpoint\"])"],"metadata":{"id":"4j7jeRhb0Zfz","executionInfo":{"status":"ok","timestamp":1759218022491,"user_tz":-180,"elapsed":12240,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["c494d8a02e1c4a7d9ed97660957fafa3","6e5a25da844849ae82abf8b127e858dc","7be641bdc7634e2a99e7346b7eac3273","f5a01bce0ddd4b33bfe67dd968636230","9ffa3db6e0044dd1880eabe7d5253431","340eddd27a594d37904be54ef8fac165","5d2660127dd74ab892442b165407878d","29174e7e82e24a83856ab9d88d5ab259","6a96d20f6a8c490ab4d67f6c2f6a7a64","e57da65ac3ac4731928672d2d2826e46","0dcc587a1854442abf86c35def9eeb34","82417566418742caa58a324a999d4f58","4ff4a412d1ce4f1086796a54d2e90c01","31056a7f9a6f4129b0b34cbade203f92","ed2951419f1241128d5976c93001be65","6d15fee69f2f480abca6d3c7a74e2c4f","7b870554cb684c2f8931370a95a81261","925230ca57554eca9a22ad2aca87c85f","38de396dae824bc696a9a08b74b297d6","c288b9c0bfb243848311106f51bdb9fe","fea4c3daf1fe48b1a2955508eebe36ea","7ec6abc1d8f544d5a9432b412a350481","900bc261aed2432682721fdc23bb95b2","4e6eff9d0874450e99f914f3c7c08af7","db710deca44045a19a7fd16cdc362e6e","a9b12480c65e470db9bd1d91c95ce984","8df54d3af535400b8fe87355557828cc","f474710b6aaa41f884e42965c8b837fa","8994b65812804e2e9d3c9d524097b224","e36e66a210a04ca3b88850de296cf40c","835dd1a29a6a4ee686719dda1b1da460","22307cbac2af41cc94a9ff446860e1e8","44cd4339463f41edab30620f9cf75b5d","2459f9b514144af59798f3e0a61a89c6","da764975d79b4456ac7f8febc7e97b97","eb791fe3759c4a47bf427fcac3959243","8c9cc802476d41b98cf4b126808cd03d","920ae9b994b74c769230ec1344ebb876","ea6cb82c767c4f0391631dd16bf15930","6d177c1bc23b4ea3b36e81c91c3bd7f1","ed8bde1a57234b4d8538a31212cc0b85","11dfbf5977d9402e9f9cfe0e732ce417","131c19b31d54413db8779bf939fa40c7","c99be27aef434cfab4c2f1ace3c35255"]},"outputId":"c86fe145-6032-4638-f243-9f6859c0f217"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c494d8a02e1c4a7d9ed97660957fafa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82417566418742caa58a324a999d4f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900bc261aed2432682721fdc23bb95b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2459f9b514144af59798f3e0a61a89c6"}},"metadata":{}}]},{"cell_type":"code","source":["def parse_spans(entities):\n","    return entities  # Уже tuples в примере\n","\n","def merge_prefixed_char_spans(entities):\n","    merged = []\n","    current = None\n","    for s, e, l in sorted(entities, key=lambda x: x[0]):\n","        if '-' in l:\n","            prefix, tag = l.split('-', 1)\n","            if prefix == 'B':\n","                if current:\n","                    merged.append(current)\n","                current = (s, e, tag)\n","            elif prefix == 'I' and current and current[2] == tag:\n","                current = (current[0], e, tag)\n","            else:\n","                if current:\n","                    merged.append(current)\n","                current = None\n","        else:\n","            if current:\n","                merged.append(current)\n","            current = None\n","    if current:\n","        merged.append(current)\n","    return merged\n","\n","def token_labels_to_char_spans(offsets, token_labels):\n","    entities = []\n","    current = None\n","    for i, (offset, label) in enumerate(zip(offsets, token_labels)):\n","        s, e = offset\n","        if s == e:  # Special\n","            continue\n","        if label == 'O':\n","            if current:\n","                entities.append(current)\n","                current = None\n","            continue\n","        if label.startswith('B-'):\n","            if current:\n","                entities.append(current)\n","            tag = label[2:]\n","            current = (s, e, 'B-' + tag)\n","        elif label.startswith('I-'):\n","            tag = label[2:]\n","            if current and current[2] == 'B-' + tag:\n","                current = (current[0], e, current[2])\n","            else:\n","                if current:\n","                    entities.append(current)\n","                current = (s, e, 'B-' + tag)\n","    if current:\n","        entities.append(current)\n","    return entities\n","\n","def tokenize_and_align_labels(text, entities, tokenizer, label2id, add_special_tokens=True):\n","    tokenized = tokenizer(text, return_offsets_mapping=True, add_special_tokens=add_special_tokens, truncation=True, max_length=512)\n","    tokens = tokenizer.convert_ids_to_tokens(tokenized['input_ids'])\n","    offsets = tokenized['offset_mapping']\n","    token_labels = ['O'] * len(tokens)\n","    for start_char, end_char, label in entities:\n","        for i, (start_tok, end_tok) in enumerate(offsets):\n","            if start_tok >= end_char:\n","                break\n","            if end_tok <= start_char or start_tok == end_tok:\n","                continue\n","            prefix, tag = label.split('-') if '-' in label else ('O', label)\n","            if start_tok == start_char:\n","                token_labels[i] = 'B-' + tag\n","            else:\n","                token_labels[i] = 'I-' + tag\n","    label_ids = []\n","    for i, l in enumerate(token_labels):\n","        if i == 0 or i == len(token_labels) - 1:\n","            label_ids.append(-100)  # Ignore special tokens\n","        else:\n","            label_ids.append(label2id.get(l, label2id['O']))\n","    tokenized['labels'] = label_ids\n","    return tokenized\n","\n","def build_label_maps_from_examples(examples):\n","    labels = set(['O'])\n","    for _, ents in examples:\n","        for _, _, l in ents:\n","            if '-' in l:\n","                prefix, tag = l.split('-')\n","                labels.add('B-' + tag)\n","                labels.add('I-' + tag)\n","    label_list = sorted(list(labels))\n","    label2id = {l: i for i, l in enumerate(label_list)}\n","    id2label = {i: l for l, i in label2id.items()}\n","    return label_list, label2id, id2label"],"metadata":{"id":"RHi0_BaOzO-0","executionInfo":{"status":"ok","timestamp":1759221971197,"user_tz":-180,"elapsed":64,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\", use_fast=True)\n","\n","examples = [\n","    (\"яйцо куриное\", [(0, 4, 'B-TYPE'), (5, 12, 'I-TYPE')]),\n","    (\"яйцо куриное 30шт\", [(0,4,'B-TYPE'), (5,12,'I-TYPE'), (13,17,'B-VOLUME')]),\n","    (\"сок 0.2 л 10%\", [(0,3,'B-TYPE'), (4,7,'B-VOLUME'), (8,9,'I-VOLUME'), (10,13,'B-PERCENT')]),\n","    (\"масло сливочное 72% 250 г President\", [(0,5,'B-TYPE'), (6,15,'I-TYPE'), (16,19,'B-PERCENT'), (20,23,'B-VOLUME'), (24,25,'I-VOLUME'), (26,35,'B-BRAND')]),\n","    (\"пиво Baltika 4.8% 0.5 л\", [(0,4,'B-TYPE'), (5,12,'B-BRAND'), (13,17,'B-PERCENT'), (18,21,'B-VOLUME'), (22,23,'I-VOLUME')]),\n","    (\"global village летняя ягода\", [(0,6,'B-BRAND'), (7,14,'I-BRAND'), (15,21,'B-TYPE'), (22,27,'I-TYPE')]),\n","    (\"arkhangel'skkhleb багет\", [(0,17,'B-BRAND'), (18,23,'B-TYPE')]),\n","    (\"aunfed\", [(0,6,'O')]),\n","    (\"bunk club\", [(0,4,'O'), (5,9,'O')]),\n","]\n","\n","# Run tests\n","for text, entities in examples:\n","    print(f\"TEXT:{text} Entities:{entities}\")\n","    parsed = entities  # if you had strings: parse_span_str(...)\n","    enc = tokenize_and_align_labels(text, parsed, tokenizer, add_special_tokens=True)\n","    tokens = enc['tokens']; offsets = enc['offsets']; tlabels = enc['token_labels']\n","    print(\"Токены:\", tokens)\n","    print(\"OFFSETS:\", offsets)\n","    print(\"TOKEN LABELS:\", tlabels)\n","    recovered = token_labels_to_char_spans(offsets, tlabels)\n","    print(\"RECOVERED CHAR-SPANS:\", recovered)\n","    merged = merge_prefixed_char_spans(parsed)\n","    # prepare expected in recovered-format: B-<BASE> for entities, 'O' for O\n","    expected = []\n","    for s,e,lab in merged:\n","        if lab == 'O':\n","            expected.append((s,e,'O'))\n","        else:\n","            expected.append((s,e,'B-' + lab))\n","    print(\"EXPECTED (merged):\", expected)\n","    ok = (recovered == expected)\n","    print(\"ROUND-TRIP OK:\", ok)\n","    if not ok:\n","        print(\"NOTE: mismatches can happen if tokenizer splits differently; inspect offsets and labels.\")\n","    print(\"-\" * 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KaFuwbUZzP9n","executionInfo":{"status":"ok","timestamp":1759222251917,"user_tz":-180,"elapsed":723,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"b8f829fd-5501-459b-ceee-1a3edc1b4e04"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["TEXT:яйцо куриное Entities:[(0, 4, 'B-TYPE'), (5, 12, 'I-TYPE')]\n","Токены: ['[CLS]', 'яйцо', 'кури', '##ное', '[SEP]']\n","OFFSETS: [(0, 0), (0, 4), (5, 9), (9, 12), (0, 0)]\n","TOKEN LABELS: ['O', 'B-TYPE', 'B-TYPE', 'I-TYPE', 'O']\n","RECOVERED CHAR-SPANS: [(0, 4, 'B-TYPE'), (5, 12, 'B-TYPE')]\n","EXPECTED (merged): [(0, 4, 'B-TYPE'), (5, 12, 'B-TYPE')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:яйцо куриное 30шт Entities:[(0, 4, 'B-TYPE'), (5, 12, 'I-TYPE'), (13, 17, 'B-VOLUME')]\n","Токены: ['[CLS]', 'яйцо', 'кури', '##ное', '30', '##шт', '[SEP]']\n","OFFSETS: [(0, 0), (0, 4), (5, 9), (9, 12), (13, 15), (15, 17), (0, 0)]\n","TOKEN LABELS: ['O', 'B-TYPE', 'B-TYPE', 'I-TYPE', 'B-VOLUME', 'I-VOLUME', 'O']\n","RECOVERED CHAR-SPANS: [(0, 4, 'B-TYPE'), (5, 12, 'B-TYPE'), (13, 17, 'B-VOLUME')]\n","EXPECTED (merged): [(0, 4, 'B-TYPE'), (5, 12, 'B-TYPE'), (13, 17, 'B-VOLUME')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:сок 0.2 л 10% Entities:[(0, 3, 'B-TYPE'), (4, 7, 'B-VOLUME'), (8, 9, 'I-VOLUME'), (10, 13, 'B-PERCENT')]\n","Токены: ['[CLS]', 'сок', '0', '.', '2', 'л', '10', '%', '[SEP]']\n","OFFSETS: [(0, 0), (0, 3), (4, 5), (5, 6), (6, 7), (8, 9), (10, 12), (12, 13), (0, 0)]\n","TOKEN LABELS: ['O', 'B-TYPE', 'B-VOLUME', 'I-VOLUME', 'I-VOLUME', 'B-VOLUME', 'B-PERCENT', 'I-PERCENT', 'O']\n","RECOVERED CHAR-SPANS: [(0, 3, 'B-TYPE'), (4, 7, 'B-VOLUME'), (8, 9, 'B-VOLUME'), (10, 13, 'B-PERCENT')]\n","EXPECTED (merged): [(0, 3, 'B-TYPE'), (4, 7, 'B-VOLUME'), (8, 9, 'B-VOLUME'), (10, 13, 'B-PERCENT')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:масло сливочное 72% 250 г President Entities:[(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT'), (20, 23, 'B-VOLUME'), (24, 25, 'I-VOLUME'), (26, 35, 'B-BRAND')]\n","Токены: ['[CLS]', 'масло', 'слив', '##очное', '72', '%', '250', 'г', 'President', '[SEP]']\n","OFFSETS: [(0, 0), (0, 5), (6, 10), (10, 15), (16, 18), (18, 19), (20, 23), (24, 25), (26, 35), (0, 0)]\n","TOKEN LABELS: ['O', 'B-TYPE', 'B-TYPE', 'I-TYPE', 'B-PERCENT', 'I-PERCENT', 'B-VOLUME', 'B-VOLUME', 'B-BRAND', 'O']\n","RECOVERED CHAR-SPANS: [(0, 5, 'B-TYPE'), (6, 15, 'B-TYPE'), (16, 19, 'B-PERCENT'), (20, 23, 'B-VOLUME'), (24, 25, 'B-VOLUME'), (26, 35, 'B-BRAND')]\n","EXPECTED (merged): [(0, 5, 'B-TYPE'), (6, 15, 'B-TYPE'), (16, 19, 'B-PERCENT'), (20, 23, 'B-VOLUME'), (24, 25, 'B-VOLUME'), (26, 35, 'B-BRAND')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:пиво Baltika 4.8% 0.5 л Entities:[(0, 4, 'B-TYPE'), (5, 12, 'B-BRAND'), (13, 17, 'B-PERCENT'), (18, 21, 'B-VOLUME'), (22, 23, 'I-VOLUME')]\n","Токены: ['[CLS]', 'пиво', 'Bal', '##ti', '##ka', '4', '.', '8', '%', '0', '.', '5', 'л', '[SEP]']\n","OFFSETS: [(0, 0), (0, 4), (5, 8), (8, 10), (10, 12), (13, 14), (14, 15), (15, 16), (16, 17), (18, 19), (19, 20), (20, 21), (22, 23), (0, 0)]\n","TOKEN LABELS: ['O', 'B-TYPE', 'B-BRAND', 'I-BRAND', 'I-BRAND', 'B-PERCENT', 'I-PERCENT', 'I-PERCENT', 'I-PERCENT', 'B-VOLUME', 'I-VOLUME', 'I-VOLUME', 'B-VOLUME', 'O']\n","RECOVERED CHAR-SPANS: [(0, 4, 'B-TYPE'), (5, 12, 'B-BRAND'), (13, 17, 'B-PERCENT'), (18, 21, 'B-VOLUME'), (22, 23, 'B-VOLUME')]\n","EXPECTED (merged): [(0, 4, 'B-TYPE'), (5, 12, 'B-BRAND'), (13, 17, 'B-PERCENT'), (18, 21, 'B-VOLUME'), (22, 23, 'B-VOLUME')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:global village летняя ягода Entities:[(0, 6, 'B-BRAND'), (7, 14, 'I-BRAND'), (15, 21, 'B-TYPE'), (22, 27, 'I-TYPE')]\n","Токены: ['[CLS]', 'gl', '##obal', 'vi', '##ll', '##age', 'летняя', 'ягод', '##а', '[SEP]']\n","OFFSETS: [(0, 0), (0, 2), (2, 6), (7, 9), (9, 11), (11, 14), (15, 21), (22, 26), (26, 27), (0, 0)]\n","TOKEN LABELS: ['O', 'B-BRAND', 'I-BRAND', 'B-BRAND', 'I-BRAND', 'I-BRAND', 'B-TYPE', 'B-TYPE', 'I-TYPE', 'O']\n","RECOVERED CHAR-SPANS: [(0, 6, 'B-BRAND'), (7, 14, 'B-BRAND'), (15, 21, 'B-TYPE'), (22, 27, 'B-TYPE')]\n","EXPECTED (merged): [(0, 6, 'B-BRAND'), (7, 14, 'B-BRAND'), (15, 21, 'B-TYPE'), (22, 27, 'B-TYPE')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:arkhangel'skkhleb багет Entities:[(0, 17, 'B-BRAND'), (18, 23, 'B-TYPE')]\n","Токены: ['[CLS]', 'ar', '##kh', '##angel', \"'\", 'sk', '##kh', '##le', '##b', 'баг', '##ет', '[SEP]']\n","OFFSETS: [(0, 0), (0, 2), (2, 4), (4, 9), (9, 10), (10, 12), (12, 14), (14, 16), (16, 17), (18, 21), (21, 23), (0, 0)]\n","TOKEN LABELS: ['O', 'B-BRAND', 'I-BRAND', 'I-BRAND', 'I-BRAND', 'I-BRAND', 'I-BRAND', 'I-BRAND', 'I-BRAND', 'B-TYPE', 'I-TYPE', 'O']\n","RECOVERED CHAR-SPANS: [(0, 17, 'B-BRAND'), (18, 23, 'B-TYPE')]\n","EXPECTED (merged): [(0, 17, 'B-BRAND'), (18, 23, 'B-TYPE')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:aunfed Entities:[(0, 6, 'O')]\n","Токены: ['[CLS]', 'au', '##n', '##fe', '##d', '[SEP]']\n","OFFSETS: [(0, 0), (0, 2), (2, 3), (3, 5), (5, 6), (0, 0)]\n","TOKEN LABELS: ['O', 'O', 'O', 'O', 'O', 'O']\n","RECOVERED CHAR-SPANS: [(0, 6, 'O')]\n","EXPECTED (merged): [(0, 6, 'O')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n","TEXT:bunk club Entities:[(0, 4, 'O'), (5, 9, 'O')]\n","Токены: ['[CLS]', 'bu', '##n', '##k', 'club', '[SEP]']\n","OFFSETS: [(0, 0), (0, 2), (2, 3), (3, 4), (5, 9), (0, 0)]\n","TOKEN LABELS: ['O', 'O', 'O', 'O', 'O', 'O']\n","RECOVERED CHAR-SPANS: [(0, 4, 'O'), (5, 9, 'O')]\n","EXPECTED (merged): [(0, 4, 'O'), (5, 9, 'O')]\n","ROUND-TRIP OK: True\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["class NERDataset(Dataset):\n","    def __init__(self, data, tokenizer, label2id):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.label2id = label2id\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text, annotations = self.data[idx]\n","        entities = annotations['entities']\n","        tokenized = tokenize_and_align_labels(text, entities, self.tokenizer, self.label2id)\n","        return {\n","            'input_ids': torch.tensor(tokenized['input_ids']),\n","            'attention_mask': torch.tensor(tokenized['attention_mask']),\n","            'labels': torch.tensor(tokenized['labels'])\n","        }\n","\n","# Обновлённый evaluate_model\n","def evaluate_model(model, eval_data, tokenizer, id2label):\n","    entity_pairs = []\n","    for text, annotations in eval_data:\n","        tokenized = tokenizer([text], padding=True, truncation=True, return_tensors=\\\"pt\\\", return_offsets_mapping=True)\n","        input_ids = tokenized[\\\"input_ids\\\"].to(model.bert.device)\n","        attention_mask = tokenized[\\\"attention_mask\\\"].to(model.bert.device)\n","        with torch.no_grad():\n","            pred = model(input_ids, attention_mask)[0]\n","        bio_labels = [id2label[p.item()] for p in pred[0]]\n","        offsets = tokenized[\\\"offset_mapping\\\"][0].tolist()\n","        pred_entities = token_labels_to_char_spans(offsets, bio_labels)\n","        true_entities = annotations['entities']\n","        entity_pairs.append((true_entities, pred_entities))\n","    return calculate_macro_f1(entity_pairs)\n","\n","# Загрузка данных\n","def load_data(file_path):\n","    df = pd.read_csv(file_path, sep=';')\n","    data = [(row['sample'], {'entities': ast.literal_eval(row['annotation'])}) for _, row in df.iterrows()]\n","    return data"],"metadata":{"id":"ViwlaKNrFIkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ueU3QeiOcsC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== ИНИЦИАЛИЗАЦИЯ МОДЕЛИ ===\")\n","model = NERModelWithCRF(len(CONFIG[\"label_list\"])).to(device)\n","optimizer = AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n","num_training_steps = CONFIG[\"num_epochs\"] * len(train_data) // CONFIG[\"batch_size\"]\n","scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","train_dataset = NERDataset(train_data, tokenizer)\n","train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n","\n","\n","metrics_df = pd.DataFrame(columns=['epoch', 'loss', 'f1_macro', 'f1_TYPE', 'f1_BRAND', 'f1_VOLUME', 'f1_PERCENT'])\n","best_f1 = 0\n","patience_counter = 0\n","best_epoch = 0\n","\n","print(\"✅ Модель и данные успешно подготовлены!\")\n","print(f\"Размер обучающей выборки: {len(train_dataset)}\")\n","print(f\"Размер валидационной выборки: {len(valid_dataset)}\")"],"metadata":{"id":"92aearUZ0hEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759185158043,"user_tz":-180,"elapsed":5455,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"54166c5d-cec0-427d-ea7c-5e23f15d545f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== ИНИЦИАЛИЗАЦИЯ МОДЕЛИ ===\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Модель и данные успешно подготовлены!\n","Размер обучающей выборки: 21792\n","Размер валидационной выборки: 5456\n"]}]},{"cell_type":"code","source":["print(\"\\n=== НАЧАЛО SCREENING ОБУЧЕНИЯ ===\")\n","try:\n","    for epoch in range(CONFIG[\"num_epochs\"]):\n","        model.train()\n","        total_loss = 0\n","        for batch in train_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","            loss = model(input_ids, attention_mask, labels)\n","\n","            # Усредняем лосс по батчу и затем получаем скаляр\n","            loss_mean = loss.mean()  # Добавляем эту строку\n","            total_loss += loss_mean.item()  # Используем усредненное значение\n","\n","            optimizer.zero_grad()\n","            loss_mean.backward()  # Используем усредненное значение для обратного распространения\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        eval_metrics = evaluate_model(model, valid_data, tokenizer)\n","        current_f1 = eval_metrics[\"f1_macro\"]\n","\n","        metrics_row = {\n","            'epoch': epoch + 1,\n","            'loss': avg_loss,\n","            **eval_metrics\n","        }\n","        metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics_row])], ignore_index=True)\n","\n","        print(f'Эпоха {epoch + 1:<3} | Loss: {avg_loss:.4f} | '\n","              f'F1-macro: {current_f1:.4f} | '\n","              f'F1-TYPE: {eval_metrics[\"f1_TYPE\"]:.4f} | '\n","              f'F1-BRAND: {eval_metrics[\"f1_BRAND\"]:.4f} | '\n","              f'F1-VOLUME: {eval_metrics[\"f1_VOLUME\"]:.4f} | '\n","              f'F1-PERCENT: {eval_metrics[\"f1_PERCENT\"]:.4f}')\n","\n","        if current_f1 > best_f1:\n","            best_f1 = current_f1\n","            best_epoch = epoch + 1\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            print(f\"⏳ Patience: {patience_counter}/{PATIENCE}\")\n","            if patience_counter >= PATIENCE:\n","                print(f\"\\n🛑 Ранняя остановка на эпохе {epoch + 1}\")\n","                print(f\"Лучший F1-macro: {best_f1:.4f} достигнут на эпохе {best_epoch}\")\n","                break\n","\n","except Exception as e:\n","    print(f'💥 Критическая ошибка: {str(e)}')\n","    print(traceback.format_exc())\n","\n","finally:\n","    # Сохранение screening модели на HF\n","    print(f\"\\n💾 Сохранение screening модели на HF: {BERT_REPO_NAME+'_screening'}\")\n","    success = save_bert_to_hf(model, tokenizer, CONFIG, BERT_REPO_NAME+'_screening', HF_TOKEN)\n","\n","    if success:\n","        print(f\"🎉 BERT screening модель успешно сохранена на HF: {BERT_REPO_NAME+'_screening'}\")\n","    else:\n","        print(\"❌ Не удалось сохранить BERT screening модель на HF\")\n","\n","    # Локальное сохранение\n","    # torch.save(model.state_dict(), f\"{MODEL_PATH}/model_screening.pt\")\n","    metrics_df.to_csv(CONFIG[\"metrics_csv\"], index=False)\n","    print(\"💾Метрики сохранены локально\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ИТОГОВЫЕ РЕЗУЛЬТАТЫ SCREENING:\")\n","print(\"=\"*80)\n","print(f\"Лучший F1-macro: {best_f1:.4f} на эпохе {best_epoch}\")\n","print(f\"Всего эпох выполнено: {len(metrics_df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IyWSwnO0jQ4","executionInfo":{"status":"ok","timestamp":1759185452489,"user_tz":-180,"elapsed":291098,"user":{"displayName":"TVLG LX6500","userId":"15785277625807876484"}},"outputId":"5256ffa4-2733-4351-bd34-f963375dc8d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== НАЧАЛО SCREENING ОБУЧЕНИЯ ===\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3202428183.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics_row])], ignore_index=True)\n"]},{"output_type":"stream","name":"stdout","text":["Эпоха 1   | Loss: 1.8344 | F1-macro: 0.0000 | F1-TYPE: 0.0000 | F1-BRAND: 0.0000 | F1-VOLUME: 0.0000 | F1-PERCENT: 0.0000\n","⏳ Patience: 1/2\n","Эпоха 2   | Loss: 0.6936 | F1-macro: 0.0000 | F1-TYPE: 0.0000 | F1-BRAND: 0.0000 | F1-VOLUME: 0.0000 | F1-PERCENT: 0.0000\n","⏳ Patience: 2/2\n","\n","🛑 Ранняя остановка на эпохе 2\n","Лучший F1-macro: 0.0000 достигнут на эпохе 0\n","\n","💾 Сохранение screening модели на HF: alexflex04/NER_cleared_data_bert_screening\n","Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","✅ Авторизация HF настроена\n","✅ Репозиторий найден: alexflex04/NER_cleared_data_bert_screening\n","❌ Ошибка сохранения BERT модели: 'NERModelWithCRF' object has no attribute 'save_pretrained'\n","❌ Не удалось сохранить BERT screening модель на HF\n","💾Метрики сохранены локально\n","\n","================================================================================\n","ИТОГОВЫЕ РЕЗУЛЬТАТЫ SCREENING:\n","================================================================================\n","Лучший F1-macro: 0.0000 на эпохе 0\n","Всего эпох выполнено: 2\n"]}]},{"cell_type":"code","source":["# Визуализация\n","plt.figure(figsize=(15, 10))\n","plt.subplot(2, 1, 1)\n","plt.plot(metrics_df['epoch'], metrics_df['loss'], 'b-', linewidth=2, label='Loss')\n","plt.axvline(x=best_epoch, color='r', linestyle='--', alpha=0.7, label=f'Лучшая эпоха ({best_epoch})')\n","plt.xlabel('Эпоха')\n","plt.ylabel('Loss')\n","plt.title('Loss по эпохам')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(metrics_df['epoch'], metrics_df['f1_macro'], 'r-', linewidth=3, label='F1-macro')\n","plt.plot(metrics_df['epoch'], metrics_df['f1_TYPE'], 'g--', label='F1-TYPE')\n","plt.plot(metrics_df['epoch'], metrics_df['f1_BRAND'], 'b--', label='F1-BRAND')\n","plt.plot(metrics_df['epoch'], metrics_df['f1_VOLUME'], 'y--', label='F1-VOLUME')\n","plt.plot(metrics_df['epoch'], metrics_df['f1_PERCENT'], 'c--', label='F1-PERCENT')\n","plt.axvline(x=best_epoch, color='r', linestyle='--', alpha=0.7, label=f'Лучшая эпоха ({best_epoch})')\n","plt.xlabel('Эпоха')\n","plt.ylabel('F1 Score')\n","plt.title('F1 Scores по эпохам')\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig(f\"{OUT_DIR}/screening_metrics.png\", dpi=300, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"a8NbgDCk0mEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n=== ПРОВЕРКА ЗАГРУЗКИ МОДЕЛИ ===\")\n","loaded_model, loaded_tokenizer, loaded_config = load_bert_from_hf(BERT_REPO_NAME+'_screening', HF_TOKEN, device)\n","\n","if loaded_model:\n","    print(\"✅ Модель успешно загружена с HF!\")\n","    test_text = \"молоко Простоквашино 2.5% 1л\"\n","    from module import HFWrapper\n","    wrapper = HFWrapper(loaded_model, loaded_tokenizer)\n","    doc = wrapper(test_text)\n","    entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","    print(f\"Тестовый текст: '{test_text}'\")\n","    print(f\"Извлеченные сущности: {entities}\")\n","\n","    # Обработка submission файла\n","    print(f\"\\n=== ОБРАБОТКА SUBMISSION ФАЙЛА ===\")\n","    process_submission_bert(\n","        model=loaded_model,\n","        tokenizer=loaded_tokenizer,\n","        input_file=CONFIG[\"submission_input\"],\n","        output_file=f\"{OUT_DIR}/submission_screening.csv\"\n","    )\n","else:\n","    print(\"❌ Не удалось загрузить модель для тестирования\")"],"metadata":{"id":"oVXcgPQDKOoV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cM7CtsGwKO5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ячейка 2: Подбор гиперпараметров (Tuning) с grid search\n","PARAM_GRID = {\n","    \"learning_rate\": [1e-5, 2e-5, 3e-5],\n","    \"batch_size\": [32, 64],\n","    \"epochs\": [10, 20],\n","    \"weight_decay\": [0.01, 0.1]\n","}\n","\n","grid_results = []\n","\n","for lr in PARAM_GRID[\"learning_rate\"]:\n","    for bsz in PARAM_GRID[\"batch_size\"]:\n","        for max_ep in PARAM_GRID[\"epochs\"]:\n","            for wd in PARAM_GRID[\"weight_decay\"]:\n","                combo = {\"learning_rate\": lr, \"batch_size\": bsz, \"epochs\": max_ep, \"weight_decay\": wd}\n","                print(f\"\\n=== Tuning combo: learning_rate={lr}, batch_size={bsz}, epochs={max_ep}, weight_decay={wd} ===\")\n","\n","                model = NERModelWithCRF(len(CONFIG[\"label_list\"])).to(device)\n","                optimizer = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n","                num_training_steps = max_ep * len(train_data) // bsz\n","                scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","                train_loader = DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n","\n","                patience_counter, best_f1, best_metrics = 0, 0.0, None\n","                for epoch in range(1, max_ep + 1):\n","                    model.train()\n","                    total_loss = 0\n","                    for batch in train_loader:\n","                        input_ids = batch[\"input_ids\"].to(device)\n","                        attention_mask = batch[\"attention_mask\"].to(device)\n","                        labels = batch[\"labels\"].to(device)\n","                        loss = model(input_ids, attention_mask, labels)\n","                        loss_mean = loss.mean()\n","                        total_loss += loss_mean.item()\n","                        optimizer.zero_grad()\n","                        loss_mean.backward()\n","                        optimizer.step()\n","                        scheduler.step()\n","\n","                    avg_loss = total_loss / len(train_loader)\n","                    metrics = evaluate_model(model, valid_data, tokenizer)\n","                    metrics[\"epoch\"] = epoch\n","                    metrics[\"loss\"] = avg_loss\n","                    current_f1 = metrics[\"f1_macro\"]\n","\n","                    print(f\"Ep {epoch} | Loss: {metrics['loss']:.4f} | F1-macro: {current_f1:.4f}\")\n","\n","                    if current_f1 > best_f1:\n","                        best_f1 = current_f1\n","                        best_metrics = metrics\n","                        patience_counter = 0\n","                    else:\n","                        patience_counter += 1\n","                        if patience_counter >= PATIENCE:\n","                            break\n","\n","                combo[\"best_f1_macro\"] = best_f1\n","                combo[\"best_metrics\"] = best_metrics\n","                grid_results.append(combo)\n","\n","# Выбор лучших параметров\n","best_combo = max(grid_results, key=lambda x: x[\"best_f1_macro\"])\n","print(\"\\nBest tuning params:\", best_combo)\n","\n","# Сохранение результатов\n","pd.DataFrame(grid_results).to_csv(f\"{OUT_DIR}/tuning_summary.csv\", index=False)\n","with open(f\"{OUT_DIR}/tuning_detailed.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(grid_results, f, ensure_ascii=False, indent=2)\n","with open(f\"{OUT_DIR}/best_combo.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump({k: v for k, v in best_combo.items() if k != \"best_metrics\"}, f, ensure_ascii=False, indent=2)\n","print(\"💾 Tuning результаты и best_combo сохранены\")\n"],"metadata":{"id":"6vKo5oFn0s2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ячейка 3: Кросс-валидация (CV) с лучшими параметрами\n","with open(f\"{OUT_DIR}/best_combo.json\", \"r\", encoding=\"utf-8\") as f:\n","    best_combo = json.load(f)\n","\n","best_lr = best_combo[\"learning_rate\"]\n","best_bsz = best_combo[\"batch_size\"]\n","best_max_ep = best_combo[\"epochs\"]\n","best_wd = best_combo[\"weight_decay\"]\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n","cv_results = []\n","fold_best_f1s = []\n","\n","for fold, (tr_idx, val_idx) in enumerate(kf.split(train_data), 1):\n","    print(f\"\\n=== CV Fold {fold} ===\")\n","    fold_train = [train_data[i] for i in tr_idx]\n","    fold_valid = [train_data[i] for i in val_idx]\n","\n","    fold_train_dataset = NERDataset(fold_train, tokenizer)\n","    fold_train_loader = DataLoader(fold_train_dataset, batch_size=best_bsz, shuffle=True)\n","\n","    model = NERModelWithCRF(len(CONFIG[\"label_list\"])).to(device)\n","    optimizer = AdamW(model.parameters(), lr=best_lr, weight_decay=best_wd)\n","    num_training_steps = best_max_ep * len(fold_train) // best_bsz\n","    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","    patience_counter, best_f1, best_metrics = 0, 0.0, None\n","    for epoch in range(1, best_max_ep + 1):\n","        model.train()\n","        total_loss = 0\n","        for batch in fold_train_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","            loss = model(input_ids, attention_mask, labels)\n","            loss_mean = loss.mean()\n","            total_loss += loss_mean.item()\n","            optimizer.zero_grad()\n","            loss_mean.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_loss = total_loss / len(fold_train_loader)\n","        metrics = evaluate_model(model, fold_valid, tokenizer)\n","        metrics[\"epoch\"] = epoch\n","        metrics[\"loss\"] = avg_loss\n","        current_f1 = metrics[\"f1_macro\"]\n","\n","        print(f\"Fold {fold} Ep {epoch} | Loss: {metrics['loss']:.4f} | F1-macro: {current_f1:.4f}\")\n","\n","        if current_f1 > best_f1:\n","            best_f1 = current_f1\n","            best_metrics = metrics\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= PATIENCE:\n","                break\n","\n","    cv_results.append({\"fold\": fold, \"best_f1_macro\": best_f1, \"best_metrics\": best_metrics})\n","    fold_best_f1s.append(best_f1)\n","\n","mean_f1 = np.mean(fold_best_f1s)\n","std_f1 = np.std(fold_best_f1s)\n","print(f\"\\nCV Results: Mean F1_macro = {mean_f1:.4f} ± {std_f1:.4f}\")\n","\n","# Сохранение результатов CV\n","pd.DataFrame(cv_results).to_csv(f\"{OUT_DIR}/cv_summary.csv\", index=False)\n","with open(f\"{OUT_DIR}/cv_detailed.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(cv_results, f, ensure_ascii=False, indent=2)\n","print(\"💾 CV результаты сохранены\")"],"metadata":{"id":"gU0AhvFT0tZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ячейка 4: Финальное обучение на объединённом датасете (train+val)\n","train_val = [(row['sample'], {'entities': ast.literal_eval(row['annotation'])}) for _, row in pd.concat([train_split, valid_data]).iterrows()]\n","train_val_dataset = NERDataset(train_val, tokenizer)\n","train_val_loader = DataLoader(train_val_dataset, batch_size=best_bsz, shuffle=True)\n","\n","model = NERModelWithCRF(len(CONFIG[\"label_list\"])).to(device)\n","optimizer = AdamW(model.parameters(), lr=best_lr, weight_decay=best_wd)\n","num_training_steps = best_max_ep * len(train_val) // best_bsz\n","scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","records = []\n","best_final_f1, patience_counter = 0.0, 0\n","for epoch in range(1, best_max_ep + 1):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_val_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        loss = model(input_ids, attention_mask, labels)\n","        loss_mean = loss.mean()\n","        total_loss += loss_mean.item()\n","        optimizer.zero_grad()\n","        loss_mean.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_loss = total_loss / len(train_val_loader)\n","    print(f\"Эпоха {epoch} | Loss: {avg_loss:.4f}\")\n","\n","# Сохранение screening модели на HF\n","    print(f\"\\n💾 Сохранение screening модели на HF: {BERT_REPO_NAME}\")\n","    success = save_bert_to_hf(model, tokenizer, CONFIG, BERT_REPO_NAME, HF_TOKEN)\n","\n","    if success:\n","        print(f\"🎉 BERT screening модель успешно сохранена на HF: {BERT_REPO_NAME}\")\n","    else:\n","        print(\"❌ Не удалось сохранить BERT screening модель на HF\")\n","# Вариант 1: Сохранение BERT-модели\n","# model.bert.save_pretrained(MODEL_PATH)\n","# Вариант 2: Экспорт в ONNX (закомментирован)\n","# dummy_input_ids = torch.randint(0, tokenizer.vocab_size, (1, 512)).to(device)\n","# dummy_attention_mask = torch.ones(1, 512).to(device)\n","# torch.onnx.export(model.bert, (dummy_input_ids, dummy_attention_mask),\n","#                   CONFIG[\"onnx_model_path\"],\n","#                   export_params=True,\n","#                   opset_version=14,  # Изменено на 14\n","#                   input_names=['input_ids', 'attention_mask'],\n","#                   output_names=['logits'],\n","#                   dynamic_axes={'input_ids': {0: 'batch', 1: 'seq'},\n","#                                 'attention_mask': {0: 'batch', 1: 'seq'},\n","#                                 'logits': {0: 'batch', 1: 'seq'}})\n","# quantize_dynamic(CONFIG[\"onnx_model_path\"], CONFIG[\"quantized_onnx_path\"], weight_type=QuantType.QUInt8)\n","# print(f\"\\nFinal model saved: {MODEL_PATH}\")"],"metadata":{"id":"D7b_w0Nd0v2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wz7v_fJW0ycg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n=== ПРОВЕРКА ЗАГРУЗКИ МОДЕЛИ ===\")\n","loaded_model, loaded_tokenizer, loaded_config = load_bert_from_hf(BERT_REPO_NAME, HF_TOKEN, device)\n","\n","if loaded_model:\n","    print(\"✅ Модель успешно загружена с HF!\")\n","    test_text = \"молоко Простоквашино 2.5% 1л\"\n","    from module import HFWrapper\n","    wrapper = HFWrapper(loaded_model, loaded_tokenizer)\n","    doc = wrapper(test_text)\n","    entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","    print(f\"Тестовый текст: '{test_text}'\")\n","    print(f\"Извлеченные сущности: {entities}\")\n","\n","    # Обработка submission файла\n","    print(f\"\\n=== ОБРАБОТКА SUBMISSION ФАЙЛА ===\")\n","    process_submission_bert(\n","        model=loaded_model,\n","        tokenizer=loaded_tokenizer,\n","        input_file=CONFIG[\"submission_input\"],\n","        output_file=f\"{OUT_DIR}/submission.csv\"\n","    )\n","else:\n","    print(\"❌ Не удалось загрузить модель для тестирования\")"],"metadata":{"id":"LZfZkz6oL3-x"},"execution_count":null,"outputs":[]}]}