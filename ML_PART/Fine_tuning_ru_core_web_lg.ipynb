{"cells":[{"cell_type":"markdown","metadata":{"id":"u7LGvw3gWYGK"},"source":["от этого файла я хочу следующее: Просто сделать nER с помощью модели из spacY потом дополнительно алгоритмически произвести BIO добавление префиксов и так с этой моделью поиграться.\n","Скорее всего эта модель будет давать слабые результаты, потому что она может только сущности распознавать, а есть такая проблема, что от контекста сильно может зависеть ответ\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58416,"status":"ok","timestamp":1759078550187,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"},"user_tz":-180},"id":"bKexHXF2qM9_","outputId":"48c1a76c-9194-45e5-e74d-e0eb98685449"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks\n","Введи GitHub PAT токен: ··········\n","Заново склонировали репу\n","fatal: destination path 'entities-extraction-x5' already exists and is not an empty directory.\n","/content/drive/MyDrive/Colab Notebooks/entities-extraction-x5/ML_PART\n","✅ Всё готово! Рабочая папка: /content/drive/MyDrive/Colab Notebooks/entities-extraction-x5/ML_PART\n"]}],"source":["from google.colab import drive\n","import getpass, os\n","\n","# === Настройка проекта ===\n","USER = \"tokarevdr\"   # твой GitHub username\n","REPO = \"entities-extraction-x5\"            # название репозитория\n","EMAIL = \"fedorov.alexander.04@gmail.com\"    # твоя почта для git\n","NAME = \"Alexander\"           # твоё имя для git\n","# === Подключение Google Drive ===\n","drive.mount('/content/drive')\n","PROJECTS_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n","%cd $PROJECTS_DIR\n","# === GitHub авторизация ===\n","token = getpass.getpass('Введи GitHub PAT токен: ')\n","os.environ[\"GITHUB_TOKEN\"] = token\n","\n","\n","# === Проверяем: если репозиторий ещё не скачан, клонируем ===\n","if not os.path.exists(f\"{PROJECTS_DIR}/{REPO}/ML PART\"):\n","    print('Заново склонировали репу')\n","    !git clone https://{USER}:{os.environ[\"GITHUB_TOKEN\"]}@github.com/{USER}/{REPO}.git\n","# === Переходим в папку проекта ===\n","%cd {REPO}/{'ML_PART'}\n","\n","# === Настройка Git ===\n","!git config --global user.email \"{EMAIL}\"\n","!git config --global user.name \"{NAME}\"\n","!git remote set-url origin https://{USER}:{os.environ[\"GITHUB_TOKEN\"]}@github.com/{USER}/{REPO}.git\n","\n","print(\"✅ Всё готово! Рабочая папка:\", os.getcwd())\n"]},{"cell_type":"code","source":["# --- Основные пути для сохранения результатов ---\n","OUT_DIR = \"OUTPUT/ru_core_web_lg\"\n","os.makedirs(OUT_DIR, exist_ok=True)       # папка для сохранения всех файлов\n","MODEL_SAVE_PATH = f\"{OUT_DIR}/final_model_best_hyperparams\"\n","GRID_SUMMARY_PATH = f\"{OUT_DIR}/grid_search_summary.csv\"\n","GRID_DETAILS_PATH = f\"{OUT_DIR}/grid_search_detailed_results.json\"\n","FINAL_METRICS_PATH = f\"{OUT_DIR}/final_training_metrics_per_epoch.csv\"\n","DATA_DIR = 'data/cleared_data/'\n","N_SPLITS = 5        # кол-во фолдов в кросс-валидации\n","\n","# --- Сетка гиперпараметров для подбора ---\n","PARAM_GRID = {\n","    \"dropout\": [0.3],\n","    \"batch_size\": [128],\n","    \"epochs\": [15]\n","}\n","\n","# --- Ранняя остановка ---\n","PATIENCE = 3      # количество эпох без улучшения F1 до остановки\n","\n","# --- Начальное состояние/Seed для воспроизводимости ---\n","SEED = 42\n","\n","# --- Имя предобученной модели (можно \"ru_core_news_lg\" или \"\" для blank) ---\n","BASE_MODEL_NAME = \"ru_core_news_lg\""],"metadata":{"id":"q-_-OtDuI7c-","executionInfo":{"status":"ok","timestamp":1759078550447,"user_tz":-180,"elapsed":257,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["! git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WTeEcfUS4vhv","executionInfo":{"status":"ok","timestamp":1759078666796,"user_tz":-180,"elapsed":116346,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}},"outputId":"cf2d350d-8898-4db1-e57a-c9d86d3fa2e2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Refresh index: 100% (50/50), done.\n","On branch NER_models\n","Your branch is up to date with 'origin/NER_models'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   Fine_tuning_ru_core_web_lg.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   Data_explorer.ipynb\u001b[m\n","\t\u001b[31mmodified:   Fine_tuning_ru_core_web_lg.ipynb\u001b[m\n","\n"]}]},{"cell_type":"code","source":["# ! git add ."],"metadata":{"id":"WZcF5qPl4kVJ","executionInfo":{"status":"ok","timestamp":1759078666815,"user_tz":-180,"elapsed":9,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1759078666833,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"},"user_tz":-180},"id":"0tZzhVrz_tSS"},"outputs":[],"source":["# ! git commit -m 'Сделал 2 норм датасета (чистый и аугментированный) + начал норм работу с моделями. Пока запустил расчет и не хватило ресурсов, надо что-то придумать'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Q04vzfJE_1fd","executionInfo":{"status":"ok","timestamp":1759078666869,"user_tz":-180,"elapsed":32,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"outputs":[],"source":["# ! git push"]},{"cell_type":"code","source":["! pip install pymorphy3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCShQRCRz1mL","executionInfo":{"status":"ok","timestamp":1759078675553,"user_tz":-180,"elapsed":8681,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}},"outputId":"42b1e88a-7f83-4f37-c0a6-1d66aa23356d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymorphy3\n","  Downloading pymorphy3-2.0.4-py3-none-any.whl.metadata (2.4 kB)\n","Collecting dawg2-python>=0.8.0 (from pymorphy3)\n","  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n","Collecting pymorphy3-dicts-ru (from pymorphy3)\n","  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n","Downloading pymorphy3-2.0.4-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n","Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n","Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.4 pymorphy3-dicts-ru-2.4.417150.4580142\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15762,"status":"ok","timestamp":1759078691328,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"},"user_tz":-180},"id":"IpLgRe_LeiQs","outputId":"1f57063e-bb01-4645-d8a3-5aca3a8290ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=223765670ff80bfcb8eaa94840ceb523f6c61086006a48ea0da5c4a34bf23427\n","  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["! pip install seqeval"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"q6_KEoVtek2a","executionInfo":{"status":"ok","timestamp":1759078704061,"user_tz":-180,"elapsed":12722,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"outputs":[],"source":["import os, json, random, time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","import spacy\n","from spacy.training.example import Example\n","from spacy.util import minibatch\n","from module import calculate_ner_metrics, calculate_macro_f1, process_submission\n","import ast"]},{"cell_type":"code","source":["def evaluate_model(model, eval_data):\n","    \"\"\"Вычисление метрик на валидационной выборке\"\"\"\n","    entity_pairs = []\n","\n","    for text, annotations in eval_data:\n","        # Получаем предсказания модели\n","        doc = model(text)\n","        pred_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","\n","        # Истинные сущности\n","        true_entities = annotations['entities']\n","\n","        entity_pairs.append((true_entities, pred_entities))\n","\n","    # Вычисляем метрики\n","    macro_f1, f1_type, f1_brand, f1_volume, f1_percent = calculate_macro_f1(entity_pairs)\n","\n","    return {\n","        'f1_macro': macro_f1,\n","        'f1_TYPE': f1_type,\n","        'f1_BRAND': f1_brand,\n","        'f1_VOLUME': f1_volume,\n","        'f1_PERCENT': f1_percent\n","    }"],"metadata":{"id":"G6Ncrk40b3JE","executionInfo":{"status":"ok","timestamp":1759078704099,"user_tz":-180,"elapsed":32,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["random.seed(SEED); np.random.seed(SEED)"],"metadata":{"id":"vv2HLejLaXVg","executionInfo":{"status":"ok","timestamp":1759078704114,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbeNkjiG3mbZ"},"source":["Загрузка данных\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2904,"status":"ok","timestamp":1759078707024,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"},"user_tz":-180},"id":"nA4F8Jzl3l8m","outputId":"a21ed670-df4f-4215-c9bf-be169ecf1f01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 21794 | Valid: 2709 | Test: 2748\n"]}],"source":["train_split = pd.read_csv(DATA_DIR+'train.csv')\n","valid_data = pd.read_csv(DATA_DIR+'val.csv')\n","print(f\"Train: {len(train_split)} | Valid: {len(valid_data)} | Test: {len(test_data)}\")"]},{"cell_type":"code","source":["train_val = pd.merge(train_split, valid_data, how='outer')"],"metadata":{"id":"T0NJp94EMgNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(valid_data.head(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N32HT7aastL","executionInfo":{"status":"ok","timestamp":1759078707075,"user_tz":-180,"elapsed":38,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}},"outputId":"baedef49-79c4-419e-c137-5b4307d76284"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["     sample           annotation\n","0     acofe        [(0, 5, 'O')]\n","1     adren  [(0, 5, 'B-BRAND')]\n","2  adrenali  [(0, 8, 'B-BRAND')]\n","3  aktimuno  [(0, 8, 'B-BRAND')]\n","4    albeni  [(0, 6, 'B-BRAND')]\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60087,"status":"ok","timestamp":1759078767160,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"},"user_tz":-180},"id":"y4xjI2HUX5dT","outputId":"285d42d7-0547-4337-b333-2afe4a6408ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ru-core-news-lg==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.8.0/ru_core_news_lg-3.8.0-py3-none-any.whl (513.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ru-core-news-lg==3.8.0) (2.0.4)\n","Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (0.9.0)\n","Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.12/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (2.4.417150.4580142)\n","Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (75.2.0)\n","Installing collected packages: ru-core-news-lg\n","Successfully installed ru-core-news-lg-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('ru_core_news_lg')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["! python3 -m spacy download ru_core_news_lg"]},{"cell_type":"markdown","metadata":{"id":"LEYDUUl3ZCqo"},"source":["Сейчас делаю вариант, где будут просто типы сразу с префиксами"]},{"cell_type":"code","source":["def create_base_nlp():\n","    try:\n","        nlp = spacy.load(BASE_MODEL)\n","        if 'ner' in nlp.pipe_names:\n","            nlp.remove_pipe('ner')\n","    except Exception:\n","        nlp = spacy.blank(\"ru\")\n","    nlp.add_pipe(\"ner\")\n","    return nlp"],"metadata":{"id":"vMd40oD4a2UY","executionInfo":{"status":"ok","timestamp":1759078767184,"user_tz":-180,"elapsed":5,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n","grid_results = []"],"metadata":{"id":"lrTLQz-TbEPS","executionInfo":{"status":"ok","timestamp":1759078767190,"user_tz":-180,"elapsed":3,"user":{"displayName":"Александр Федоров","userId":"11558309455709398811"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for drop in PARAM_GRID[\"dropout\"]:\n","    for bsz in PARAM_GRID[\"batch_size\"]:\n","        for max_ep in PARAM_GRID[\"epochs\"]:\n","            combo = {\"dropout\": drop, \"batch\": bsz, \"epochs\": max_ep, \"folds\": []}\n","            print(f\"\\n=== Combo dropout={drop}, batch={bsz}, epochs={max_ep} ===\")\n","            fold_best = []\n","\n","            for fold, (tr_idx, val_idx) in enumerate(kf.split(train_val), 1):\n","                # Получаем подмножества DataFrame\n","                train_df = train_split.iloc[tr_idx]\n","                valid_df = train_split.iloc[val_idx]\n","\n","                # Преобразуем в списки кортежей (text, annotations)\n","                fold_train = [(row['sample'], {'entities': ast.literal_eval(row['annotation'])})\n","                              for _, row in train_df.iterrows()]\n","                fold_valid = [(row['sample'], {'entities': ast.literal_eval(row['annotation'])})\n","                              for _, row in valid_df.iterrows()]\n","\n","                # Создаём модель и добавляем метки из fold_train\n","                nlp = create_base_nlp()\n","                for _, ann in fold_train:\n","                    for ent in ann[\"entities\"]:\n","                        nlp.get_pipe(\"ner\").add_label(ent[2])\n","\n","                optimizer = nlp.begin_training()\n","\n","                patience_counter, best_f1, best_metrics = 0, 0.0, None\n","                for epoch in range(1, max_ep + 1):\n","                    random.shuffle(fold_train)\n","                    losses = {}\n","                    for batch in minibatch(fold_train, size=bsz):\n","                        examples = [Example.from_dict(nlp.make_doc(t), a) for t, a in batch]\n","                        nlp.update(examples, drop=drop, losses=losses)\n","\n","                    metrics = evaluate_model(nlp, fold_valid)\n","                    metrics[\"epoch\"] = epoch\n","                    metrics[\"loss\"] = losses.get(\"ner\", 0.0)\n","                    combo[\"folds\"].append({\"fold\": fold, **metrics})\n","\n","                    print(f\"Fold {fold} Ep {epoch} | \" +\n","                          \" | \".join(f\"{k}:{metrics[k]:.4f}\" for k in metrics if k != 'epoch'))\n","\n","                    if metrics[\"f1_macro\"] > best_f1:\n","                        best_f1, best_metrics, patience_counter = metrics[\"f1_macro\"], metrics, 0\n","                    else:\n","                        patience_counter += 1\n","                        if patience_counter >= PATIENCE:\n","                            break\n","\n","                fold_best.append(best_f1)\n","                print(f\"Best F1_macro fold {fold}: {best_f1:.4f}\")\n","\n","            combo[\"mean_f1\"] = float(np.mean(fold_best))\n","            grid_results.append(combo)\n","            print(f\"Mean F1 across folds: {combo['mean_f1']:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuZv6IHHbEw3","outputId":"7866e578-baf6-4d32-d518-f2397aae53eb"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","=== Combo dropout=0.3, batch=64, epochs=20 ===\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"стиральный  порошок\" with entities \"[(0, 11, 'B-TYPE'), (12, 19, 'I-TYPE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  черкаши\" with entities \"[(0, 9, 'B-TYPE'), (10, 17, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"lnd\" with entities \"[(1, 4, 'O')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  окраина\" with entities \"[(0, 9, 'B-TYPE'), (10, 17, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Fold 1 Ep 1 | f1_macro:0.4829 | f1_TYPE:0.8807 | f1_BRAND:0.7176 | f1_VOLUME:0.3333 | f1_PERCENT:0.0000 | loss:9605.0537\n","Fold 1 Ep 2 | f1_macro:0.6416 | f1_TYPE:0.9075 | f1_BRAND:0.7885 | f1_VOLUME:0.4706 | f1_PERCENT:0.4000 | loss:5365.1089\n","Fold 1 Ep 3 | f1_macro:0.7403 | f1_TYPE:0.9223 | f1_BRAND:0.8245 | f1_VOLUME:0.7143 | f1_PERCENT:0.5000 | loss:4141.7124\n","Fold 1 Ep 4 | f1_macro:0.7218 | f1_TYPE:0.9306 | f1_BRAND:0.8411 | f1_VOLUME:0.6154 | f1_PERCENT:0.5000 | loss:3528.3345\n","Fold 1 Ep 5 | f1_macro:0.7355 | f1_TYPE:0.9313 | f1_BRAND:0.8441 | f1_VOLUME:0.6667 | f1_PERCENT:0.5000 | loss:3061.1946\n","Fold 1 Ep 6 | f1_macro:0.5930 | f1_TYPE:0.9223 | f1_BRAND:0.8246 | f1_VOLUME:0.6250 | f1_PERCENT:0.0000 | loss:2675.9397\n","Best F1_macro fold 1: 0.7403\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  окраи\" with entities \"[(0, 9, 'B-TYPE'), (10, 15, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"вкуный\" with entities \"[(1, 7, 'O')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  клински\" with entities \"[(0, 9, 'B-TYPE'), (10, 17, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  черкашин\" with entities \"[(0, 9, 'B-TYPE'), (10, 18, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"емян\" with entities \"[(1, 5, 'O')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"шпикачки  клинск\" with entities \"[(0, 9, 'B-TYPE'), (10, 16, 'B-BRAND')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 Ep 1 | f1_macro:0.3904 | f1_TYPE:0.8669 | f1_BRAND:0.6945 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:9652.1777\n","Fold 2 Ep 2 | f1_macro:0.4648 | f1_TYPE:0.9057 | f1_BRAND:0.7870 | f1_VOLUME:0.1667 | f1_PERCENT:0.0000 | loss:5263.2222\n","Fold 2 Ep 3 | f1_macro:0.6478 | f1_TYPE:0.9213 | f1_BRAND:0.8200 | f1_VOLUME:0.5833 | f1_PERCENT:0.2667 | loss:4127.8174\n","Fold 2 Ep 4 | f1_macro:0.5900 | f1_TYPE:0.9229 | f1_BRAND:0.8108 | f1_VOLUME:0.4444 | f1_PERCENT:0.1818 | loss:3489.7183\n","Fold 2 Ep 5 | f1_macro:0.6842 | f1_TYPE:0.9213 | f1_BRAND:0.8156 | f1_VOLUME:0.7500 | f1_PERCENT:0.2500 | loss:3046.5217\n","Fold 2 Ep 6 | f1_macro:0.7234 | f1_TYPE:0.9287 | f1_BRAND:0.8409 | f1_VOLUME:0.6957 | f1_PERCENT:0.4286 | loss:2606.9802\n","Fold 2 Ep 7 | f1_macro:0.7142 | f1_TYPE:0.9266 | f1_BRAND:0.8354 | f1_VOLUME:0.7200 | f1_PERCENT:0.3750 | loss:2412.5081\n","Fold 2 Ep 8 | f1_macro:0.7357 | f1_TYPE:0.9266 | f1_BRAND:0.8345 | f1_VOLUME:0.7200 | f1_PERCENT:0.4615 | loss:2170.0825\n","Fold 2 Ep 9 | f1_macro:0.8578 | f1_TYPE:0.9205 | f1_BRAND:0.8274 | f1_VOLUME:0.7500 | f1_PERCENT:0.9333 | loss:1981.4280\n","Fold 2 Ep 10 | f1_macro:0.6922 | f1_TYPE:0.9268 | f1_BRAND:0.8334 | f1_VOLUME:0.6087 | f1_PERCENT:0.4000 | loss:1703.6588\n","Fold 2 Ep 11 | f1_macro:0.6543 | f1_TYPE:0.9241 | f1_BRAND:0.8302 | f1_VOLUME:0.7200 | f1_PERCENT:0.1429 | loss:1645.3971\n","Fold 2 Ep 12 | f1_macro:0.8865 | f1_TYPE:0.9274 | f1_BRAND:0.8361 | f1_VOLUME:0.7826 | f1_PERCENT:1.0000 | loss:1430.8944\n","Fold 2 Ep 13 | f1_macro:0.8571 | f1_TYPE:0.9324 | f1_BRAND:0.8427 | f1_VOLUME:0.7200 | f1_PERCENT:0.9333 | loss:1364.0824\n","Fold 2 Ep 14 | f1_macro:0.7952 | f1_TYPE:0.9248 | f1_BRAND:0.8272 | f1_VOLUME:0.5714 | f1_PERCENT:0.8571 | loss:1272.9534\n","Fold 2 Ep 15 | f1_macro:0.8160 | f1_TYPE:0.9274 | f1_BRAND:0.8365 | f1_VOLUME:0.5000 | f1_PERCENT:1.0000 | loss:1239.5933\n","Best F1_macro fold 2: 0.8865\n","Fold 3 Ep 1 | f1_macro:0.5009 | f1_TYPE:0.8767 | f1_BRAND:0.7271 | f1_VOLUME:0.4000 | f1_PERCENT:0.0000 | loss:9632.7529\n","Fold 3 Ep 2 | f1_macro:0.5682 | f1_TYPE:0.8995 | f1_BRAND:0.7851 | f1_VOLUME:0.5882 | f1_PERCENT:0.0000 | loss:5325.2900\n","Fold 3 Ep 3 | f1_macro:0.7437 | f1_TYPE:0.9166 | f1_BRAND:0.8203 | f1_VOLUME:0.5714 | f1_PERCENT:0.6667 | loss:4201.5708\n","Fold 3 Ep 4 | f1_macro:0.7286 | f1_TYPE:0.9198 | f1_BRAND:0.8281 | f1_VOLUME:0.6667 | f1_PERCENT:0.5000 | loss:3481.0930\n","Fold 3 Ep 5 | f1_macro:0.7512 | f1_TYPE:0.9258 | f1_BRAND:0.8411 | f1_VOLUME:0.6667 | f1_PERCENT:0.5714 | loss:3048.5217\n","Fold 3 Ep 6 | f1_macro:0.6596 | f1_TYPE:0.9295 | f1_BRAND:0.8453 | f1_VOLUME:0.3636 | f1_PERCENT:0.5000 | loss:2595.8086\n","Fold 3 Ep 7 | f1_macro:0.6858 | f1_TYPE:0.9271 | f1_BRAND:0.8448 | f1_VOLUME:0.5714 | f1_PERCENT:0.4000 | loss:2286.2903\n","Fold 3 Ep 8 | f1_macro:0.7782 | f1_TYPE:0.9256 | f1_BRAND:0.8538 | f1_VOLUME:0.6667 | f1_PERCENT:0.6667 | loss:2072.4482\n","Fold 3 Ep 9 | f1_macro:0.7623 | f1_TYPE:0.9272 | f1_BRAND:0.8398 | f1_VOLUME:0.6154 | f1_PERCENT:0.6667 | loss:1794.0029\n","Fold 3 Ep 10 | f1_macro:0.7501 | f1_TYPE:0.9254 | f1_BRAND:0.8371 | f1_VOLUME:0.6667 | f1_PERCENT:0.5714 | loss:1595.9331\n","Fold 3 Ep 11 | f1_macro:0.8994 | f1_TYPE:0.9275 | f1_BRAND:0.8367 | f1_VOLUME:0.8333 | f1_PERCENT:1.0000 | loss:1545.7487\n","Fold 3 Ep 12 | f1_macro:0.8406 | f1_TYPE:0.9304 | f1_BRAND:0.8475 | f1_VOLUME:0.7273 | f1_PERCENT:0.8571 | loss:1438.7583\n","Fold 3 Ep 13 | f1_macro:0.6641 | f1_TYPE:0.9300 | f1_BRAND:0.8407 | f1_VOLUME:0.6000 | f1_PERCENT:0.2857 | loss:1245.2423\n","Fold 3 Ep 14 | f1_macro:0.7649 | f1_TYPE:0.9275 | f1_BRAND:0.8367 | f1_VOLUME:0.5455 | f1_PERCENT:0.7500 | loss:1184.7167\n","Best F1_macro fold 3: 0.8994\n","Fold 4 Ep 1 | f1_macro:0.3945 | f1_TYPE:0.8806 | f1_BRAND:0.6975 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:9773.8418\n","Fold 4 Ep 2 | f1_macro:0.7200 | f1_TYPE:0.9078 | f1_BRAND:0.7991 | f1_VOLUME:0.3158 | f1_PERCENT:0.8571 | loss:5291.5361\n","Fold 4 Ep 3 | f1_macro:0.6784 | f1_TYPE:0.9221 | f1_BRAND:0.8208 | f1_VOLUME:0.5263 | f1_PERCENT:0.4444 | loss:4214.1973\n","Fold 4 Ep 4 | f1_macro:0.7871 | f1_TYPE:0.9276 | f1_BRAND:0.8346 | f1_VOLUME:0.6364 | f1_PERCENT:0.7500 | loss:3526.3682\n","Fold 4 Ep 5 | f1_macro:0.8183 | f1_TYPE:0.9282 | f1_BRAND:0.8451 | f1_VOLUME:0.8333 | f1_PERCENT:0.6667 | loss:3066.0327\n","Fold 4 Ep 6 | f1_macro:0.8723 | f1_TYPE:0.9272 | f1_BRAND:0.8421 | f1_VOLUME:0.7200 | f1_PERCENT:1.0000 | loss:2723.8052\n","Fold 4 Ep 7 | f1_macro:0.7595 | f1_TYPE:0.9325 | f1_BRAND:0.8482 | f1_VOLUME:0.8571 | f1_PERCENT:0.4000 | loss:2415.9204\n","Fold 4 Ep 8 | f1_macro:0.9101 | f1_TYPE:0.9278 | f1_BRAND:0.8428 | f1_VOLUME:0.8696 | f1_PERCENT:1.0000 | loss:2102.6301\n","Fold 4 Ep 9 | f1_macro:0.8800 | f1_TYPE:0.9261 | f1_BRAND:0.8374 | f1_VOLUME:0.9565 | f1_PERCENT:0.8000 | loss:1870.5188\n","Fold 4 Ep 10 | f1_macro:0.9108 | f1_TYPE:0.9322 | f1_BRAND:0.8415 | f1_VOLUME:0.8696 | f1_PERCENT:1.0000 | loss:1711.3575\n","Fold 4 Ep 11 | f1_macro:0.8737 | f1_TYPE:0.9312 | f1_BRAND:0.8369 | f1_VOLUME:0.8696 | f1_PERCENT:0.8571 | loss:1587.2449\n","Fold 4 Ep 12 | f1_macro:0.8406 | f1_TYPE:0.9289 | f1_BRAND:0.8333 | f1_VOLUME:0.8000 | f1_PERCENT:0.8000 | loss:1413.5665\n","Fold 4 Ep 13 | f1_macro:0.8750 | f1_TYPE:0.9303 | f1_BRAND:0.8432 | f1_VOLUME:0.8696 | f1_PERCENT:0.8571 | loss:1316.3868\n","Best F1_macro fold 4: 0.9108\n","Fold 5 Ep 1 | f1_macro:0.4707 | f1_TYPE:0.8803 | f1_BRAND:0.7166 | f1_VOLUME:0.2857 | f1_PERCENT:0.0000 | loss:9674.4873\n","Fold 5 Ep 2 | f1_macro:0.5526 | f1_TYPE:0.9052 | f1_BRAND:0.7971 | f1_VOLUME:0.2222 | f1_PERCENT:0.2857 | loss:5217.0093\n","Fold 5 Ep 3 | f1_macro:0.8189 | f1_TYPE:0.9222 | f1_BRAND:0.8263 | f1_VOLUME:0.7273 | f1_PERCENT:0.8000 | loss:4190.2930\n","Fold 5 Ep 4 | f1_macro:0.7237 | f1_TYPE:0.9198 | f1_BRAND:0.8293 | f1_VOLUME:0.6000 | f1_PERCENT:0.5455 | loss:3445.5461\n","Fold 5 Ep 5 | f1_macro:0.6355 | f1_TYPE:0.9256 | f1_BRAND:0.8385 | f1_VOLUME:0.4444 | f1_PERCENT:0.3333 | loss:3042.0654\n","Fold 5 Ep 6 | f1_macro:0.7216 | f1_TYPE:0.9237 | f1_BRAND:0.8353 | f1_VOLUME:0.4000 | f1_PERCENT:0.7273 | loss:2668.7722\n","Best F1_macro fold 5: 0.8189\n","Mean F1 across folds: 0.8512\n","\n","=== Combo dropout=0.3, batch=128, epochs=20 ===\n","Fold 1 Ep 1 | f1_macro:0.4610 | f1_TYPE:0.8577 | f1_BRAND:0.6531 | f1_VOLUME:0.3333 | f1_PERCENT:0.0000 | loss:11833.2236\n","Fold 1 Ep 2 | f1_macro:0.5667 | f1_TYPE:0.9001 | f1_BRAND:0.7665 | f1_VOLUME:0.6000 | f1_PERCENT:0.0000 | loss:5948.3994\n","Fold 1 Ep 3 | f1_macro:0.6381 | f1_TYPE:0.9166 | f1_BRAND:0.8025 | f1_VOLUME:0.5000 | f1_PERCENT:0.3333 | loss:4614.7510\n","Fold 1 Ep 4 | f1_macro:0.6107 | f1_TYPE:0.9276 | f1_BRAND:0.8290 | f1_VOLUME:0.3529 | f1_PERCENT:0.3333 | loss:3835.0295\n","Fold 1 Ep 5 | f1_macro:0.7228 | f1_TYPE:0.9291 | f1_BRAND:0.8371 | f1_VOLUME:0.6250 | f1_PERCENT:0.5000 | loss:3356.0679\n","Fold 1 Ep 6 | f1_macro:0.6921 | f1_TYPE:0.9312 | f1_BRAND:0.8372 | f1_VOLUME:0.5000 | f1_PERCENT:0.5000 | loss:3018.6831\n","Fold 1 Ep 7 | f1_macro:0.6845 | f1_TYPE:0.9295 | f1_BRAND:0.8372 | f1_VOLUME:0.5714 | f1_PERCENT:0.4000 | loss:2633.3271\n","Fold 1 Ep 8 | f1_macro:0.6858 | f1_TYPE:0.9293 | f1_BRAND:0.8424 | f1_VOLUME:0.5714 | f1_PERCENT:0.4000 | loss:2392.7634\n","Best F1_macro fold 1: 0.7228\n","Fold 2 Ep 1 | f1_macro:0.3761 | f1_TYPE:0.8510 | f1_BRAND:0.6533 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:11859.0029\n","Fold 2 Ep 2 | f1_macro:0.4674 | f1_TYPE:0.9007 | f1_BRAND:0.7466 | f1_VOLUME:0.2222 | f1_PERCENT:0.0000 | loss:5868.7935\n","Fold 2 Ep 3 | f1_macro:0.6460 | f1_TYPE:0.9141 | f1_BRAND:0.7954 | f1_VOLUME:0.1053 | f1_PERCENT:0.7692 | loss:4515.7051\n","Fold 2 Ep 4 | f1_macro:0.6322 | f1_TYPE:0.9210 | f1_BRAND:0.8141 | f1_VOLUME:0.5714 | f1_PERCENT:0.2222 | loss:3759.1287\n","Fold 2 Ep 5 | f1_macro:0.6577 | f1_TYPE:0.9290 | f1_BRAND:0.8401 | f1_VOLUME:0.4615 | f1_PERCENT:0.4000 | loss:3363.8770\n","Fold 2 Ep 6 | f1_macro:0.5638 | f1_TYPE:0.9319 | f1_BRAND:0.8473 | f1_VOLUME:0.4762 | f1_PERCENT:0.0000 | loss:2968.8379\n","Fold 2 Ep 7 | f1_macro:0.8110 | f1_TYPE:0.9318 | f1_BRAND:0.8455 | f1_VOLUME:0.6667 | f1_PERCENT:0.8000 | loss:2646.6868\n","Fold 2 Ep 8 | f1_macro:0.8395 | f1_TYPE:0.9291 | f1_BRAND:0.8462 | f1_VOLUME:0.7826 | f1_PERCENT:0.8000 | loss:2371.4404\n","Fold 2 Ep 9 | f1_macro:0.7699 | f1_TYPE:0.9246 | f1_BRAND:0.8319 | f1_VOLUME:0.6087 | f1_PERCENT:0.7143 | loss:2131.9771\n","Fold 2 Ep 10 | f1_macro:0.8401 | f1_TYPE:0.9291 | f1_BRAND:0.8424 | f1_VOLUME:0.7000 | f1_PERCENT:0.8889 | loss:1887.8903\n","Fold 2 Ep 11 | f1_macro:0.7879 | f1_TYPE:0.9275 | f1_BRAND:0.8345 | f1_VOLUME:0.8182 | f1_PERCENT:0.5714 | loss:1704.9719\n","Fold 2 Ep 12 | f1_macro:0.8109 | f1_TYPE:0.9288 | f1_BRAND:0.8482 | f1_VOLUME:0.6667 | f1_PERCENT:0.8000 | loss:1642.3904\n","Fold 2 Ep 13 | f1_macro:0.8108 | f1_TYPE:0.9236 | f1_BRAND:0.8348 | f1_VOLUME:0.8182 | f1_PERCENT:0.6667 | loss:1520.1749\n","Best F1_macro fold 2: 0.8401\n","Fold 3 Ep 1 | f1_macro:0.4443 | f1_TYPE:0.8490 | f1_BRAND:0.6425 | f1_VOLUME:0.2857 | f1_PERCENT:0.0000 | loss:11619.9746\n","Fold 3 Ep 2 | f1_macro:0.5753 | f1_TYPE:0.9002 | f1_BRAND:0.7761 | f1_VOLUME:0.6250 | f1_PERCENT:0.0000 | loss:6017.1221\n","Fold 3 Ep 3 | f1_macro:0.5748 | f1_TYPE:0.9077 | f1_BRAND:0.8032 | f1_VOLUME:0.5882 | f1_PERCENT:0.0000 | loss:4725.9224\n","Fold 3 Ep 4 | f1_macro:0.5280 | f1_TYPE:0.9206 | f1_BRAND:0.8279 | f1_VOLUME:0.3636 | f1_PERCENT:0.0000 | loss:3873.8928\n","Fold 3 Ep 5 | f1_macro:0.7434 | f1_TYPE:0.9264 | f1_BRAND:0.8349 | f1_VOLUME:0.5455 | f1_PERCENT:0.6667 | loss:3255.5598\n","Fold 3 Ep 6 | f1_macro:0.7485 | f1_TYPE:0.9301 | f1_BRAND:0.8365 | f1_VOLUME:0.7273 | f1_PERCENT:0.5000 | loss:2897.3784\n","Fold 3 Ep 7 | f1_macro:0.7524 | f1_TYPE:0.9324 | f1_BRAND:0.8392 | f1_VOLUME:0.6667 | f1_PERCENT:0.5714 | loss:2616.6313\n","Fold 3 Ep 8 | f1_macro:0.7543 | f1_TYPE:0.9260 | f1_BRAND:0.8243 | f1_VOLUME:0.6000 | f1_PERCENT:0.6667 | loss:2325.8909\n","Fold 3 Ep 9 | f1_macro:0.8200 | f1_TYPE:0.9243 | f1_BRAND:0.8319 | f1_VOLUME:0.6667 | f1_PERCENT:0.8571 | loss:2038.8743\n","Fold 3 Ep 10 | f1_macro:0.8227 | f1_TYPE:0.9320 | f1_BRAND:0.8351 | f1_VOLUME:0.6667 | f1_PERCENT:0.8571 | loss:1868.0349\n","Fold 3 Ep 11 | f1_macro:0.7200 | f1_TYPE:0.9321 | f1_BRAND:0.8310 | f1_VOLUME:0.5455 | f1_PERCENT:0.5714 | loss:1760.2539\n","Fold 3 Ep 12 | f1_macro:0.7730 | f1_TYPE:0.9268 | f1_BRAND:0.8320 | f1_VOLUME:0.6667 | f1_PERCENT:0.6667 | loss:1577.3071\n","Fold 3 Ep 13 | f1_macro:0.7611 | f1_TYPE:0.9300 | f1_BRAND:0.8324 | f1_VOLUME:0.6154 | f1_PERCENT:0.6667 | loss:1389.2261\n","Best F1_macro fold 3: 0.8227\n","Fold 4 Ep 1 | f1_macro:0.4074 | f1_TYPE:0.8537 | f1_BRAND:0.6332 | f1_VOLUME:0.1429 | f1_PERCENT:0.0000 | loss:11676.9238\n","Fold 4 Ep 2 | f1_macro:0.5812 | f1_TYPE:0.8930 | f1_BRAND:0.7463 | f1_VOLUME:0.2857 | f1_PERCENT:0.4000 | loss:5920.5161\n","Fold 4 Ep 3 | f1_macro:0.6419 | f1_TYPE:0.9084 | f1_BRAND:0.7956 | f1_VOLUME:0.3636 | f1_PERCENT:0.5000 | loss:4617.8174\n","Fold 4 Ep 4 | f1_macro:0.7752 | f1_TYPE:0.9177 | f1_BRAND:0.8209 | f1_VOLUME:0.6957 | f1_PERCENT:0.6667 | loss:3800.1443\n","Fold 4 Ep 5 | f1_macro:0.7316 | f1_TYPE:0.9276 | f1_BRAND:0.8323 | f1_VOLUME:0.5000 | f1_PERCENT:0.6667 | loss:3379.7639\n","Fold 4 Ep 6 | f1_macro:0.8761 | f1_TYPE:0.9293 | f1_BRAND:0.8485 | f1_VOLUME:0.8696 | f1_PERCENT:0.8571 | loss:2976.9304\n","Fold 4 Ep 7 | f1_macro:0.8850 | f1_TYPE:0.9309 | f1_BRAND:0.8353 | f1_VOLUME:0.9167 | f1_PERCENT:0.8571 | loss:2645.8220\n","Fold 4 Ep 8 | f1_macro:0.7459 | f1_TYPE:0.9323 | f1_BRAND:0.8381 | f1_VOLUME:0.8800 | f1_PERCENT:0.3333 | loss:2348.2012\n","Fold 4 Ep 9 | f1_macro:0.8466 | f1_TYPE:0.9304 | f1_BRAND:0.8365 | f1_VOLUME:0.8696 | f1_PERCENT:0.7500 | loss:2164.9302\n","Fold 4 Ep 10 | f1_macro:0.8258 | f1_TYPE:0.9276 | f1_BRAND:0.8291 | f1_VOLUME:0.8800 | f1_PERCENT:0.6667 | loss:1963.0774\n","Best F1_macro fold 4: 0.8850\n","Fold 5 Ep 1 | f1_macro:0.4576 | f1_TYPE:0.8452 | f1_BRAND:0.6520 | f1_VOLUME:0.3333 | f1_PERCENT:0.0000 | loss:12111.9922\n","Fold 5 Ep 2 | f1_macro:0.4497 | f1_TYPE:0.8842 | f1_BRAND:0.7145 | f1_VOLUME:0.2000 | f1_PERCENT:0.0000 | loss:6071.8418\n","Fold 5 Ep 3 | f1_macro:0.7267 | f1_TYPE:0.9048 | f1_BRAND:0.7897 | f1_VOLUME:0.5455 | f1_PERCENT:0.6667 | loss:4694.4849\n","Fold 5 Ep 4 | f1_macro:0.6990 | f1_TYPE:0.9239 | f1_BRAND:0.8265 | f1_VOLUME:0.5455 | f1_PERCENT:0.5000 | loss:3858.7146\n","Fold 5 Ep 5 | f1_macro:0.6192 | f1_TYPE:0.9208 | f1_BRAND:0.8288 | f1_VOLUME:0.7273 | f1_PERCENT:0.0000 | loss:3335.2810\n","Fold 5 Ep 6 | f1_macro:0.8683 | f1_TYPE:0.9217 | f1_BRAND:0.8291 | f1_VOLUME:0.8889 | f1_PERCENT:0.8333 | loss:3061.6013\n","Fold 5 Ep 7 | f1_macro:0.8079 | f1_TYPE:0.9261 | f1_BRAND:0.8389 | f1_VOLUME:0.6667 | f1_PERCENT:0.8000 | loss:2672.4473\n","Fold 5 Ep 8 | f1_macro:0.7899 | f1_TYPE:0.9253 | f1_BRAND:0.8345 | f1_VOLUME:0.8000 | f1_PERCENT:0.6000 | loss:2410.1982\n","Fold 5 Ep 9 | f1_macro:0.7886 | f1_TYPE:0.9248 | f1_BRAND:0.8357 | f1_VOLUME:0.6667 | f1_PERCENT:0.7273 | loss:2222.7185\n","Best F1_macro fold 5: 0.8683\n","Mean F1 across folds: 0.8278\n","\n","=== Combo dropout=0.4, batch=64, epochs=20 ===\n","Fold 1 Ep 1 | f1_macro:0.3862 | f1_TYPE:0.8645 | f1_BRAND:0.6802 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:10786.0703\n","Fold 1 Ep 2 | f1_macro:0.5121 | f1_TYPE:0.8956 | f1_BRAND:0.7528 | f1_VOLUME:0.4000 | f1_PERCENT:0.0000 | loss:6151.3823\n","Fold 1 Ep 3 | f1_macro:0.5562 | f1_TYPE:0.9116 | f1_BRAND:0.7967 | f1_VOLUME:0.2667 | f1_PERCENT:0.2500 | loss:4976.5356\n","Fold 1 Ep 4 | f1_macro:0.7285 | f1_TYPE:0.9245 | f1_BRAND:0.8229 | f1_VOLUME:0.6667 | f1_PERCENT:0.5000 | loss:4271.6060\n","Fold 1 Ep 5 | f1_macro:0.6948 | f1_TYPE:0.9257 | f1_BRAND:0.8285 | f1_VOLUME:0.6250 | f1_PERCENT:0.4000 | loss:3833.6018\n","Fold 1 Ep 6 | f1_macro:0.6425 | f1_TYPE:0.9285 | f1_BRAND:0.8334 | f1_VOLUME:0.3636 | f1_PERCENT:0.4444 | loss:3456.9966\n","Fold 1 Ep 7 | f1_macro:0.6203 | f1_TYPE:0.9294 | f1_BRAND:0.8376 | f1_VOLUME:0.7143 | f1_PERCENT:0.0000 | loss:3195.2754\n","Best F1_macro fold 1: 0.7285\n","Fold 2 Ep 1 | f1_macro:0.3737 | f1_TYPE:0.8489 | f1_BRAND:0.6458 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:10976.9531\n","Fold 2 Ep 2 | f1_macro:0.5084 | f1_TYPE:0.8791 | f1_BRAND:0.7192 | f1_VOLUME:0.2353 | f1_PERCENT:0.2000 | loss:6186.9824\n","Fold 2 Ep 3 | f1_macro:0.5966 | f1_TYPE:0.9085 | f1_BRAND:0.7922 | f1_VOLUME:0.2857 | f1_PERCENT:0.4000 | loss:4973.8633\n","Fold 2 Ep 4 | f1_macro:0.6521 | f1_TYPE:0.9133 | f1_BRAND:0.8071 | f1_VOLUME:0.2727 | f1_PERCENT:0.6154 | loss:4260.5664\n","Fold 2 Ep 5 | f1_macro:0.7941 | f1_TYPE:0.9240 | f1_BRAND:0.8239 | f1_VOLUME:0.5714 | f1_PERCENT:0.8571 | loss:3783.4104\n","Fold 2 Ep 6 | f1_macro:0.7030 | f1_TYPE:0.9303 | f1_BRAND:0.8363 | f1_VOLUME:0.5455 | f1_PERCENT:0.5000 | loss:3450.8784\n","Fold 2 Ep 7 | f1_macro:0.7788 | f1_TYPE:0.9265 | f1_BRAND:0.8264 | f1_VOLUME:0.6957 | f1_PERCENT:0.6667 | loss:3166.1289\n","Fold 2 Ep 8 | f1_macro:0.8153 | f1_TYPE:0.9283 | f1_BRAND:0.8361 | f1_VOLUME:0.7826 | f1_PERCENT:0.7143 | loss:2888.1560\n","Fold 2 Ep 9 | f1_macro:0.7875 | f1_TYPE:0.9273 | f1_BRAND:0.8379 | f1_VOLUME:0.6154 | f1_PERCENT:0.7692 | loss:2727.0798\n","Fold 2 Ep 10 | f1_macro:0.8145 | f1_TYPE:0.9273 | f1_BRAND:0.8351 | f1_VOLUME:0.6957 | f1_PERCENT:0.8000 | loss:2505.6060\n","Fold 2 Ep 11 | f1_macro:0.8648 | f1_TYPE:0.9272 | f1_BRAND:0.8363 | f1_VOLUME:0.6957 | f1_PERCENT:1.0000 | loss:2312.0840\n","Fold 2 Ep 12 | f1_macro:0.8475 | f1_TYPE:0.9235 | f1_BRAND:0.8297 | f1_VOLUME:0.6957 | f1_PERCENT:0.9412 | loss:2164.5190\n","Fold 2 Ep 13 | f1_macro:0.7470 | f1_TYPE:0.9244 | f1_BRAND:0.8310 | f1_VOLUME:0.7619 | f1_PERCENT:0.4706 | loss:2030.2626\n","Fold 2 Ep 14 | f1_macro:0.8394 | f1_TYPE:0.9230 | f1_BRAND:0.8269 | f1_VOLUME:0.6667 | f1_PERCENT:0.9412 | loss:1982.2769\n","Best F1_macro fold 2: 0.8648\n","Fold 3 Ep 1 | f1_macro:0.4465 | f1_TYPE:0.8568 | f1_BRAND:0.6792 | f1_VOLUME:0.2500 | f1_PERCENT:0.0000 | loss:10731.6328\n","Fold 3 Ep 2 | f1_macro:0.5370 | f1_TYPE:0.8935 | f1_BRAND:0.7543 | f1_VOLUME:0.5000 | f1_PERCENT:0.0000 | loss:6117.0156\n","Fold 3 Ep 3 | f1_macro:0.5907 | f1_TYPE:0.9047 | f1_BRAND:0.7916 | f1_VOLUME:0.6667 | f1_PERCENT:0.0000 | loss:4938.0059\n","Fold 3 Ep 4 | f1_macro:0.7318 | f1_TYPE:0.9082 | f1_BRAND:0.8046 | f1_VOLUME:0.7143 | f1_PERCENT:0.5000 | loss:4222.4419\n","Fold 3 Ep 5 | f1_macro:0.7185 | f1_TYPE:0.9221 | f1_BRAND:0.8269 | f1_VOLUME:0.6250 | f1_PERCENT:0.5000 | loss:3785.2280\n","Fold 3 Ep 6 | f1_macro:0.8825 | f1_TYPE:0.9283 | f1_BRAND:0.8323 | f1_VOLUME:0.7692 | f1_PERCENT:1.0000 | loss:3372.6240\n","Fold 3 Ep 7 | f1_macro:0.8556 | f1_TYPE:0.9285 | f1_BRAND:0.8366 | f1_VOLUME:0.8000 | f1_PERCENT:0.8571 | loss:3083.9805\n","Fold 3 Ep 8 | f1_macro:0.7198 | f1_TYPE:0.9281 | f1_BRAND:0.8260 | f1_VOLUME:0.6250 | f1_PERCENT:0.5000 | loss:2909.0474\n","Fold 3 Ep 9 | f1_macro:0.7046 | f1_TYPE:0.9325 | f1_BRAND:0.8413 | f1_VOLUME:0.4444 | f1_PERCENT:0.6000 | loss:2639.1104\n","Best F1_macro fold 3: 0.8825\n","Fold 4 Ep 1 | f1_macro:0.3759 | f1_TYPE:0.8597 | f1_BRAND:0.6437 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:10568.4678\n","Fold 4 Ep 2 | f1_macro:0.5401 | f1_TYPE:0.8870 | f1_BRAND:0.7304 | f1_VOLUME:0.1429 | f1_PERCENT:0.4000 | loss:6115.2559\n","Fold 4 Ep 3 | f1_macro:0.7054 | f1_TYPE:0.9032 | f1_BRAND:0.7904 | f1_VOLUME:0.4615 | f1_PERCENT:0.6667 | loss:5014.3755\n","Fold 4 Ep 4 | f1_macro:0.6884 | f1_TYPE:0.9129 | f1_BRAND:0.8147 | f1_VOLUME:0.4545 | f1_PERCENT:0.5714 | loss:4313.9233\n","Fold 4 Ep 5 | f1_macro:0.7830 | f1_TYPE:0.9205 | f1_BRAND:0.8247 | f1_VOLUME:0.7200 | f1_PERCENT:0.6667 | loss:3817.4656\n","Fold 4 Ep 6 | f1_macro:0.8150 | f1_TYPE:0.9275 | f1_BRAND:0.8326 | f1_VOLUME:0.8333 | f1_PERCENT:0.6667 | loss:3549.4648\n","Fold 4 Ep 7 | f1_macro:0.8180 | f1_TYPE:0.9293 | f1_BRAND:0.8427 | f1_VOLUME:0.8333 | f1_PERCENT:0.6667 | loss:3158.6580\n","Fold 4 Ep 8 | f1_macro:0.7328 | f1_TYPE:0.9232 | f1_BRAND:0.8414 | f1_VOLUME:0.9167 | f1_PERCENT:0.2500 | loss:2959.1760\n","Fold 4 Ep 9 | f1_macro:0.8836 | f1_TYPE:0.9260 | f1_BRAND:0.8346 | f1_VOLUME:0.9167 | f1_PERCENT:0.8571 | loss:2749.1240\n","Fold 4 Ep 10 | f1_macro:0.8125 | f1_TYPE:0.9274 | f1_BRAND:0.8358 | f1_VOLUME:0.7368 | f1_PERCENT:0.7500 | loss:2524.0850\n","Fold 4 Ep 11 | f1_macro:0.8135 | f1_TYPE:0.9237 | f1_BRAND:0.8305 | f1_VOLUME:0.8333 | f1_PERCENT:0.6667 | loss:2426.1030\n","Fold 4 Ep 12 | f1_macro:0.7718 | f1_TYPE:0.9316 | f1_BRAND:0.8524 | f1_VOLUME:0.6364 | f1_PERCENT:0.6667 | loss:2214.1421\n","Best F1_macro fold 4: 0.8836\n","Fold 5 Ep 1 | f1_macro:0.3852 | f1_TYPE:0.8622 | f1_BRAND:0.6786 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:10974.6152\n","Fold 5 Ep 2 | f1_macro:0.5414 | f1_TYPE:0.8839 | f1_BRAND:0.7364 | f1_VOLUME:0.5455 | f1_PERCENT:0.0000 | loss:6218.5127\n","Fold 5 Ep 3 | f1_macro:0.5420 | f1_TYPE:0.9077 | f1_BRAND:0.7987 | f1_VOLUME:0.4615 | f1_PERCENT:0.0000 | loss:5033.9019\n","Fold 5 Ep 4 | f1_macro:0.7405 | f1_TYPE:0.9027 | f1_BRAND:0.7928 | f1_VOLUME:0.6000 | f1_PERCENT:0.6667 | loss:4254.8848\n","Fold 5 Ep 5 | f1_macro:0.6384 | f1_TYPE:0.9215 | f1_BRAND:0.8319 | f1_VOLUME:0.8000 | f1_PERCENT:0.0000 | loss:3805.5876\n","Fold 5 Ep 6 | f1_macro:0.7873 | f1_TYPE:0.9222 | f1_BRAND:0.8271 | f1_VOLUME:0.6000 | f1_PERCENT:0.8000 | loss:3416.3591\n","Fold 5 Ep 7 | f1_macro:0.7323 | f1_TYPE:0.9273 | f1_BRAND:0.8354 | f1_VOLUME:0.5000 | f1_PERCENT:0.6667 | loss:3133.2627\n","Fold 5 Ep 8 | f1_macro:0.8230 | f1_TYPE:0.9274 | f1_BRAND:0.8373 | f1_VOLUME:0.7273 | f1_PERCENT:0.8000 | loss:2877.7214\n","Fold 5 Ep 9 | f1_macro:0.7315 | f1_TYPE:0.9255 | f1_BRAND:0.8340 | f1_VOLUME:0.5000 | f1_PERCENT:0.6667 | loss:2618.2725\n","Fold 5 Ep 10 | f1_macro:0.8043 | f1_TYPE:0.9253 | f1_BRAND:0.8375 | f1_VOLUME:0.7273 | f1_PERCENT:0.7273 | loss:2474.2239\n","Fold 5 Ep 11 | f1_macro:0.7888 | f1_TYPE:0.9249 | f1_BRAND:0.8364 | f1_VOLUME:0.6667 | f1_PERCENT:0.7273 | loss:2303.9102\n","Best F1_macro fold 5: 0.8230\n","Mean F1 across folds: 0.8365\n","\n","=== Combo dropout=0.4, batch=128, epochs=20 ===\n","Fold 1 Ep 1 | f1_macro:0.4215 | f1_TYPE:0.8402 | f1_BRAND:0.6236 | f1_VOLUME:0.2222 | f1_PERCENT:0.0000 | loss:13055.5830\n","Fold 1 Ep 2 | f1_macro:0.4814 | f1_TYPE:0.8711 | f1_BRAND:0.6909 | f1_VOLUME:0.3636 | f1_PERCENT:0.0000 | loss:6921.9580\n","Fold 1 Ep 3 | f1_macro:0.6173 | f1_TYPE:0.9003 | f1_BRAND:0.7612 | f1_VOLUME:0.3077 | f1_PERCENT:0.5000 | loss:5586.8574\n","Fold 1 Ep 4 | f1_macro:0.6052 | f1_TYPE:0.9145 | f1_BRAND:0.7921 | f1_VOLUME:0.7143 | f1_PERCENT:0.0000 | loss:4815.1665\n","Fold 1 Ep 5 | f1_macro:0.5399 | f1_TYPE:0.9151 | f1_BRAND:0.8002 | f1_VOLUME:0.4444 | f1_PERCENT:0.0000 | loss:4102.1875\n","Fold 1 Ep 6 | f1_macro:0.6882 | f1_TYPE:0.9280 | f1_BRAND:0.8249 | f1_VOLUME:0.5000 | f1_PERCENT:0.5000 | loss:3756.5269\n","Fold 1 Ep 7 | f1_macro:0.5832 | f1_TYPE:0.9242 | f1_BRAND:0.8203 | f1_VOLUME:0.5882 | f1_PERCENT:0.0000 | loss:3509.4858\n","Fold 1 Ep 8 | f1_macro:0.6382 | f1_TYPE:0.9291 | f1_BRAND:0.8288 | f1_VOLUME:0.4615 | f1_PERCENT:0.3333 | loss:3182.3169\n","Fold 1 Ep 9 | f1_macro:0.6692 | f1_TYPE:0.9342 | f1_BRAND:0.8417 | f1_VOLUME:0.6154 | f1_PERCENT:0.2857 | loss:2980.4573\n","Best F1_macro fold 1: 0.6882\n","Fold 2 Ep 1 | f1_macro:0.3671 | f1_TYPE:0.8389 | f1_BRAND:0.6295 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:12653.3633\n","Fold 2 Ep 2 | f1_macro:0.4267 | f1_TYPE:0.8690 | f1_BRAND:0.6840 | f1_VOLUME:0.1538 | f1_PERCENT:0.0000 | loss:6749.1006\n","Fold 2 Ep 3 | f1_macro:0.4135 | f1_TYPE:0.8961 | f1_BRAND:0.7580 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:5476.6997\n","Fold 2 Ep 4 | f1_macro:0.5258 | f1_TYPE:0.9118 | f1_BRAND:0.7914 | f1_VOLUME:0.4000 | f1_PERCENT:0.0000 | loss:4663.4312\n","Fold 2 Ep 5 | f1_macro:0.6486 | f1_TYPE:0.9117 | f1_BRAND:0.8067 | f1_VOLUME:0.4762 | f1_PERCENT:0.4000 | loss:4094.7390\n","Fold 2 Ep 6 | f1_macro:0.5991 | f1_TYPE:0.9185 | f1_BRAND:0.8169 | f1_VOLUME:0.2609 | f1_PERCENT:0.4000 | loss:3726.7769\n","Fold 2 Ep 7 | f1_macro:0.7393 | f1_TYPE:0.9272 | f1_BRAND:0.8312 | f1_VOLUME:0.5833 | f1_PERCENT:0.6154 | loss:3422.8201\n","Fold 2 Ep 8 | f1_macro:0.6864 | f1_TYPE:0.9273 | f1_BRAND:0.8316 | f1_VOLUME:0.7200 | f1_PERCENT:0.2667 | loss:3195.7629\n","Fold 2 Ep 9 | f1_macro:0.7230 | f1_TYPE:0.9260 | f1_BRAND:0.8289 | f1_VOLUME:0.5217 | f1_PERCENT:0.6154 | loss:2888.1199\n","Fold 2 Ep 10 | f1_macro:0.8392 | f1_TYPE:0.9318 | f1_BRAND:0.8423 | f1_VOLUME:0.7826 | f1_PERCENT:0.8000 | loss:2767.2751\n","Fold 2 Ep 11 | f1_macro:0.8920 | f1_TYPE:0.9291 | f1_BRAND:0.8406 | f1_VOLUME:0.8571 | f1_PERCENT:0.9412 | loss:2593.2974\n","Fold 2 Ep 12 | f1_macro:0.7141 | f1_TYPE:0.9308 | f1_BRAND:0.8452 | f1_VOLUME:0.7273 | f1_PERCENT:0.3529 | loss:2483.5999\n","Fold 2 Ep 13 | f1_macro:0.8755 | f1_TYPE:0.9280 | f1_BRAND:0.8406 | f1_VOLUME:0.8000 | f1_PERCENT:0.9333 | loss:2320.8699\n","Fold 2 Ep 14 | f1_macro:0.8185 | f1_TYPE:0.9253 | f1_BRAND:0.8374 | f1_VOLUME:0.6364 | f1_PERCENT:0.8750 | loss:2137.0129\n","Best F1_macro fold 2: 0.8920\n","Fold 3 Ep 1 | f1_macro:0.3627 | f1_TYPE:0.8319 | f1_BRAND:0.6189 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:12589.7031\n","Fold 3 Ep 2 | f1_macro:0.5659 | f1_TYPE:0.8812 | f1_BRAND:0.7155 | f1_VOLUME:0.6667 | f1_PERCENT:0.0000 | loss:6700.5815\n","Fold 3 Ep 3 | f1_macro:0.6911 | f1_TYPE:0.8930 | f1_BRAND:0.7605 | f1_VOLUME:0.6667 | f1_PERCENT:0.4444 | loss:5394.7295\n","Fold 3 Ep 4 | f1_macro:0.7734 | f1_TYPE:0.9078 | f1_BRAND:0.8050 | f1_VOLUME:0.7143 | f1_PERCENT:0.6667 | loss:4702.2173\n","Fold 3 Ep 5 | f1_macro:0.8781 | f1_TYPE:0.9175 | f1_BRAND:0.8255 | f1_VOLUME:0.7692 | f1_PERCENT:1.0000 | loss:4252.3164\n","Fold 3 Ep 6 | f1_macro:0.7148 | f1_TYPE:0.9181 | f1_BRAND:0.8300 | f1_VOLUME:0.6667 | f1_PERCENT:0.4444 | loss:3739.6860\n","Fold 3 Ep 7 | f1_macro:0.7971 | f1_TYPE:0.9224 | f1_BRAND:0.8302 | f1_VOLUME:0.7692 | f1_PERCENT:0.6667 | loss:3392.1965\n","Fold 3 Ep 8 | f1_macro:0.8992 | f1_TYPE:0.9239 | f1_BRAND:0.8395 | f1_VOLUME:0.8333 | f1_PERCENT:1.0000 | loss:3224.9170\n","Fold 3 Ep 9 | f1_macro:0.6430 | f1_TYPE:0.9244 | f1_BRAND:0.8394 | f1_VOLUME:0.4444 | f1_PERCENT:0.3636 | loss:2876.2991\n","Fold 3 Ep 10 | f1_macro:0.7770 | f1_TYPE:0.9205 | f1_BRAND:0.8376 | f1_VOLUME:0.6000 | f1_PERCENT:0.7500 | loss:2695.8308\n","Fold 3 Ep 11 | f1_macro:0.8331 | f1_TYPE:0.9247 | f1_BRAND:0.8383 | f1_VOLUME:0.7692 | f1_PERCENT:0.8000 | loss:2476.2998\n","Best F1_macro fold 3: 0.8992\n","Fold 4 Ep 1 | f1_macro:0.3602 | f1_TYPE:0.8380 | f1_BRAND:0.6029 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:13113.2754\n","Fold 4 Ep 2 | f1_macro:0.4570 | f1_TYPE:0.8749 | f1_BRAND:0.6865 | f1_VOLUME:0.2667 | f1_PERCENT:0.0000 | loss:7068.6846\n","Fold 4 Ep 3 | f1_macro:0.4971 | f1_TYPE:0.8935 | f1_BRAND:0.7615 | f1_VOLUME:0.3333 | f1_PERCENT:0.0000 | loss:5644.7158\n","Fold 4 Ep 4 | f1_macro:0.6002 | f1_TYPE:0.9004 | f1_BRAND:0.7848 | f1_VOLUME:0.3158 | f1_PERCENT:0.4000 | loss:4824.3330\n","Fold 4 Ep 5 | f1_macro:0.7433 | f1_TYPE:0.9177 | f1_BRAND:0.8176 | f1_VOLUME:0.6667 | f1_PERCENT:0.5714 | loss:4193.3555\n","Fold 4 Ep 6 | f1_macro:0.6643 | f1_TYPE:0.9250 | f1_BRAND:0.8322 | f1_VOLUME:0.5000 | f1_PERCENT:0.4000 | loss:3859.3879\n","Fold 4 Ep 7 | f1_macro:0.7090 | f1_TYPE:0.9276 | f1_BRAND:0.8382 | f1_VOLUME:0.7368 | f1_PERCENT:0.3333 | loss:3474.9646\n","Fold 4 Ep 8 | f1_macro:0.6843 | f1_TYPE:0.9226 | f1_BRAND:0.8311 | f1_VOLUME:0.5833 | f1_PERCENT:0.4000 | loss:3250.3276\n","Best F1_macro fold 4: 0.7433\n","Fold 5 Ep 1 | f1_macro:0.3712 | f1_TYPE:0.8432 | f1_BRAND:0.6417 | f1_VOLUME:0.0000 | f1_PERCENT:0.0000 | loss:12627.1816\n","Fold 5 Ep 2 | f1_macro:0.5038 | f1_TYPE:0.8711 | f1_BRAND:0.6996 | f1_VOLUME:0.4444 | f1_PERCENT:0.0000 | loss:6856.6836\n","Fold 5 Ep 3 | f1_macro:0.4625 | f1_TYPE:0.8931 | f1_BRAND:0.7571 | f1_VOLUME:0.2000 | f1_PERCENT:0.0000 | loss:5578.1675\n","Fold 5 Ep 4 | f1_macro:0.6657 | f1_TYPE:0.9028 | f1_BRAND:0.7884 | f1_VOLUME:0.5714 | f1_PERCENT:0.4000 | loss:4697.3604\n","Fold 5 Ep 5 | f1_macro:0.7331 | f1_TYPE:0.9126 | f1_BRAND:0.8077 | f1_VOLUME:0.5455 | f1_PERCENT:0.6667 | loss:4229.2241\n","Fold 5 Ep 6 | f1_macro:0.7365 | f1_TYPE:0.9195 | f1_BRAND:0.8265 | f1_VOLUME:0.6000 | f1_PERCENT:0.6000 | loss:3722.5918\n","Fold 5 Ep 7 | f1_macro:0.6799 | f1_TYPE:0.9241 | f1_BRAND:0.8317 | f1_VOLUME:0.6000 | f1_PERCENT:0.3636 | loss:3451.2017\n","Fold 5 Ep 8 | f1_macro:0.7694 | f1_TYPE:0.9233 | f1_BRAND:0.8270 | f1_VOLUME:0.6000 | f1_PERCENT:0.7273 | loss:3150.3533\n","Fold 5 Ep 9 | f1_macro:0.6308 | f1_TYPE:0.9200 | f1_BRAND:0.8215 | f1_VOLUME:0.6000 | f1_PERCENT:0.1818 | loss:2942.6741\n","Fold 5 Ep 10 | f1_macro:0.7389 | f1_TYPE:0.9242 | f1_BRAND:0.8314 | f1_VOLUME:0.6000 | f1_PERCENT:0.6000 | loss:2724.0215\n","Fold 5 Ep 11 | f1_macro:0.7709 | f1_TYPE:0.9259 | f1_BRAND:0.8305 | f1_VOLUME:0.6000 | f1_PERCENT:0.7273 | loss:2601.3193\n","Fold 5 Ep 12 | f1_macro:0.7678 | f1_TYPE:0.9230 | f1_BRAND:0.8209 | f1_VOLUME:0.6000 | f1_PERCENT:0.7273 | loss:2355.0918\n","Fold 5 Ep 13 | f1_macro:0.7768 | f1_TYPE:0.9257 | f1_BRAND:0.8361 | f1_VOLUME:0.5455 | f1_PERCENT:0.8000 | loss:2278.5691\n","Fold 5 Ep 14 | f1_macro:0.7733 | f1_TYPE:0.9286 | f1_BRAND:0.8375 | f1_VOLUME:0.6000 | f1_PERCENT:0.7273 | loss:2171.6868\n","Fold 5 Ep 15 | f1_macro:0.7724 | f1_TYPE:0.9252 | f1_BRAND:0.8370 | f1_VOLUME:0.6000 | f1_PERCENT:0.7273 | loss:1974.9281\n"]}]},{"cell_type":"code","source":["best_combo = max(grid_results, key=lambda x: x[\"mean_f1\"])\n","print(\"\\nBest hyperparams:\",\n","      f\"dropout={best_combo['dropout']}, batch={best_combo['batch']}, epochs={best_combo['epochs']}, \"\n","      f\"mean F1={best_combo['mean_f1']:.4f}\")\n"],"metadata":{"id":"MqjTllepbHFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame([{\n","    \"dropout\":c[\"dropout\"], \"batch\":c[\"batch\"], \"epochs\":c[\"epochs\"], \"mean_f1\":c[\"mean_f1\"]\n","} for c in grid_results]).to_csv(GRID_SUMMARY_PATH, index=False)\n","with open(GRID_DETAILS_PATH,\"w\",encoding=\"utf-8\") as f: json.dump(grid_results,f,ensure_ascii=False,indent=2)\n"],"metadata":{"id":"M7je68q2bImo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nrszUulV1Lsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp_final = create_base_nlp()\n","for _, ann in train_val:\n","    for ent in ann[\"entities\"]:\n","        nlp_final.get_pipe(\"ner\").add_label(ent[2])\n","print(ner.labels)\n","optimizer = nlp_final.begin_training()\n","\n","records = []\n","best_final_f1, patience_counter = 0.0, 0\n","for epoch in range(1, best_combo[\"epochs\"] + 1):\n","    random.shuffle(train_val)\n","    losses = {}\n","    for batch in minibatch(train_val, size=best_combo[\"batch\"]):\n","        examples = [Example.from_dict(nlp_final.make_doc(t), a) for t,a in batch]\n","        nlp_final.update(examples, drop=best_combo[\"dropout\"], losses=losses)\n","\n","    metrics = evaluate_model(nlp_final, valid_data)\n","    metrics[\"epoch\"] = epoch\n","    metrics[\"loss\"]  = losses.get(\"ner\", 0.0)\n","    records.append(metrics)\n","\n","    # вывод метрик (ВСЕ как в module.py)\n","    print(f\"Final Ep {epoch} | \" +\n","          \" | \".join(f\"{k}:{metrics[k]:.4f}\" for k in metrics if k!='epoch'))\n","\n","    if metrics[\"f1_macro\"] > best_final_f1:\n","        best_final_f1, patience_counter = metrics[\"f1_macro\"], 0\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= PATIENCE:\n","            print(\"Early stop final training\"); break\n"],"metadata":{"id":"xfbje14rbKxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(records).to_csv(FINAL_METRICS_CSV, index=False)\n","nlp_final.to_disk(MODEL_SAVE_PATH)\n","print(f\"\\nFinal model saved: {MODEL_SAVE_PATH}\")\n","print(\"Metrics per epoch saved:\", FINAL_METRICS_CSV)\n","\n","# ---------- 5. Метрики на тесте ----------\n","test_metrics = evaluate_model(nlp_final, test_data)\n","print(\"\\n=== Test metrics for best hyperparams ===\")\n","for k, v in test_metrics.items():\n","    print(f\"{k}: {v:.4f}\")"],"metadata":{"id":"6VE6hWXMbOuP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IpyQPufHYCq6"},"source":["---------------------------------------------------------------------------------------------\n","Вот все что ниже пока вообще не интересует, ни обработка ни остальное. Это все старое, стратегия поменялась."]},{"cell_type":"markdown","metadata":{"id":"sv38yPt1X64R"},"source":["Именно на них были ошибки в обучении предыдущем. А просто двойные пробелы не должны оказывать влияние на обучение => сделаю другую функцию, которая будет проверять что 0 <= start < end <= len и заменять вот такой стремный пробел на нормальный. Прежнюю сохраню на всякий."]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}